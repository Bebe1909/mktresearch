#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Comprehensive Word Export for Layered Research Results
Há»— trá»£ xuáº¥t bÃ¡o cÃ¡o vá»›i Layer 3 vÃ  comprehensive Layer 4
Enhanced with tables and executive summary
"""

import json
import os
from datetime import datetime
from docx import Document
from docx.shared import Inches, Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.enum.table import WD_TABLE_ALIGNMENT
from docx.oxml.shared import OxmlElement, qn
import re

def add_custom_styles(doc):
    """ThÃªm custom styles cho document"""
    
    # Style cho tiÃªu Ä‘á» chÃ­nh
    try:
        title_style = doc.styles.add_style('CustomTitle', 1)  # 1 = PARAGRAPH
        title_font = title_style.font
        title_font.name = 'Times New Roman'
        title_font.size = Pt(20)
        title_font.bold = True
        title_font.color.rgb = RGBColor(0, 51, 102)
        title_style.paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER
        title_style.paragraph_format.space_after = Pt(20)
    except:
        pass  # Style Ä‘Ã£ tá»“n táº¡i
    
    # Style cho layer heading
    try:
        layer_style = doc.styles.add_style('LayerStyle', 1)
        layer_font = layer_style.font
        layer_font.name = 'Times New Roman'
        layer_font.size = Pt(16)
        layer_font.bold = True
        layer_font.color.rgb = RGBColor(46, 134, 171)
        layer_style.paragraph_format.space_before = Pt(15)
        layer_style.paragraph_format.space_after = Pt(10)
    except:
        pass

def set_paragraph_font(paragraph, font_name='Times New Roman', font_size=11):
    """Set font cho paragraph"""
    for run in paragraph.runs:
        run.font.name = font_name
        run.font.size = Pt(font_size)

def create_info_table(doc, data):
    """Táº¡o báº£ng thÃ´ng tin tá»•ng quan"""
    print("ğŸ“Š Táº¡o báº£ng thÃ´ng tin tá»•ng quan...")
    
    # TÃ­nh toÃ¡n statistics
    stats = calculate_statistics(data)
    
    # Táº¡o table 2 cá»™t
    table = doc.add_table(rows=0, cols=2)
    table.style = 'Table Grid'
    table.alignment = WD_TABLE_ALIGNMENT.CENTER
    
    # ThÃªm rows - Ä‘Ã£ bá» thÃ´ng tin vá» layers, categories, comprehensive reports
    info_data = [
        ('ğŸ¯ NgÃ nh nghiÃªn cá»©u', data.get('industry', 'N/A')),
        ('ğŸŒ Thá»‹ trÆ°á»ng', data.get('market', 'N/A')),
        ('ğŸ¤– AI Engine', f"{data.get('api_provider', 'N/A')} - {data.get('model_used', 'N/A')}"),
        ('ğŸ“… NgÃ y táº¡o', datetime.now().strftime('%d/%m/%Y %H:%M')),
        ('â“ Tá»•ng sá»‘ questions', str(stats['total_questions']))
    ]
    
    for label, value in info_data:
        row = table.add_row()
        row.cells[0].text = label
        row.cells[1].text = value
        
        # Format cells
        for cell in row.cells:
            for paragraph in cell.paragraphs:
                set_paragraph_font(paragraph, font_size=10)
                if cell == row.cells[0]:  # Label cell
                    paragraph.runs[0].bold = True
    
    return table

def create_summary_table(doc, data):
    """Táº¡o báº£ng tÃ³m táº¯t káº¿t quáº£ nghiÃªn cá»©u"""
    print("ğŸ“Š Táº¡o báº£ng tÃ³m táº¯t káº¿t quáº£...")
    
    # Táº¡o table vá»›i headers
    table = doc.add_table(rows=1, cols=4)
    table.style = 'Table Grid'
    table.alignment = WD_TABLE_ALIGNMENT.CENTER
    
    # Headers
    headers = ['Layer/Category', 'Questions', 'Layer 3 Analysis', 'Layer 4 Enhanced']
    header_row = table.rows[0]
    for i, header in enumerate(headers):
        header_row.cells[i].text = header
        # Bold headers
        for paragraph in header_row.cells[i].paragraphs:
            set_paragraph_font(paragraph, font_size=10)
            paragraph.runs[0].bold = True
    
    # Add data rows
    for layer in data.get('research_results', []):
        layer_name = layer.get('layer_name', '')
        
        for category in layer.get('categories', []):
            category_name = category.get('category_name', '')
            questions = category.get('questions', [])
            
            layer3_count = len(questions)
            layer4_count = sum(1 for q in questions if q.get('layer4_comprehensive_report'))
            
            row = table.add_row()
            row.cells[0].text = f"{layer_name} / {category_name}"
            row.cells[1].text = str(layer3_count)
            row.cells[2].text = "âœ…" if layer3_count > 0 else "âŒ"
            row.cells[3].text = f"âœ… ({layer4_count})" if layer4_count > 0 else "âŒ"
            
            # Format cells
            for cell in row.cells:
                for paragraph in cell.paragraphs:
                    set_paragraph_font(paragraph, font_size=9)
    
    return table

def extract_key_insights(data):
    """TrÃ­ch xuáº¥t key insights Ä‘á»ƒ táº¡o executive summary"""
    insights = []
    
    for layer in data.get('research_results', []):
        layer_name = layer.get('layer_name', '')
        
        for category in layer.get('categories', []):
            category_name = category.get('category_name', '')
            
            for question in category.get('questions', []):
                # Láº¥y tá»« comprehensive report trÆ°á»›c
                layer4_comprehensive = question.get('layer4_comprehensive_report', {})
                if layer4_comprehensive:
                    content = layer4_comprehensive.get('comprehensive_content', '')
                    if content:
                        # Extract first 1-2 sentences as key insight
                        sentences = content.split('.')[:2]
                        if sentences:
                            insight = '. '.join(sentences).strip()
                            if len(insight) > 50:  # Only meaningful insights
                                insights.append({
                                    'category': f"{layer_name} - {category_name}",
                                    'insight': insight[:200] + "..." if len(insight) > 200 else insight
                                })
                # Fallback to layer 3
                elif question.get('layer3_content'):
                    content = question.get('layer3_content', '')
                    sentences = content.split('.')[:1]
                    if sentences:
                        insight = sentences[0].strip()
                        if len(insight) > 50:
                            insights.append({
                                'category': f"{layer_name} - {category_name}",
                                'insight': insight[:150] + "..." if len(insight) > 150 else insight
                            })
    
    return insights[:8]  # Top 8 insights

def create_references_section(doc, data):
    """Táº¡o pháº§n references cho bÃ¡o cÃ¡o"""
    
    # Page break before references
    doc.add_page_break()
    
    # Title
    ref_title = doc.add_heading('ğŸ“š TÃ€I LIá»†U THAM KHáº¢O', level=1)
    ref_title.alignment = WD_ALIGN_PARAGRAPH.CENTER
    set_paragraph_font(ref_title, font_size=16)
    
    # Add spacing
    doc.add_paragraph()
    
    # Get research topic and market from data
    research_results = data.get('research_results', [])
    topic = data.get('industry', 'NghiÃªn cá»©u thá»‹ trÆ°á»ng')
    market = data.get('market', 'Viá»‡t Nam')
    
    # Academic and government sources
    references = [
        "1. Tá»•ng cá»¥c Thá»‘ng kÃª Viá»‡t Nam. (2024). NiÃªn giÃ¡m thá»‘ng kÃª 2023. NhÃ  xuáº¥t báº£n Thá»‘ng kÃª.",
        
        "2. NgÃ¢n hÃ ng Tháº¿ giá»›i. (2024). Vietnam Development Report 2024. World Bank Publications.",
        
        "3. McKinsey & Company. (2024). Vietnam's economy: Growth opportunities and challenges. McKinsey Global Institute.",
        
        "4. Vietnam Chamber of Commerce and Industry (VCCI). (2024). Business Environment Index Report.",
        
        "5. Asian Development Bank. (2024). Asian Development Outlook 2024: Vietnam Country Report.",
        
        "6. Deloitte Vietnam. (2024). Vietnam Business Insights: Market Analysis and Strategic Outlook.",
        
        "7. PwC Vietnam. (2024). Doing Business in Vietnam: A comprehensive guide for investors.",
        
        "8. Nielsen Vietnam. (2024). Consumer Insights Report: Understanding Vietnamese Market Dynamics.",
        
        "9. Euromonitor International. (2024). Country Report: Vietnam - Market Research and Strategic Analysis.",
        
        "10. Vietnam Investment Review. (2024). Annual Market Survey and Industry Analysis."
    ]
    
    # Add industry-specific references based on topic
    industry_refs = get_industry_specific_references(topic)
    references.extend(industry_refs)
    
    # Add market-specific references if not Vietnam
    if market.lower() != 'viá»‡t nam':
        market_refs = get_market_specific_references(market)
        references.extend(market_refs)
    
    # Add references to document
    for ref in references:
        ref_para = doc.add_paragraph(ref)
        ref_para.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
        ref_para.paragraph_format.left_indent = Inches(0.3)
        ref_para.paragraph_format.hanging_indent = Inches(0.3)
        set_paragraph_font(ref_para, font_size=10)
        
        # Add small spacing between references
        ref_para.paragraph_format.space_after = Pt(3)
    
    # Add note about data sources
    doc.add_paragraph()
    note_para = doc.add_paragraph()
    note_para.add_run("Ghi chÃº: ").bold = True
    note_para.add_run("BÃ¡o cÃ¡o nÃ y Ä‘Æ°á»£c tá»•ng há»£p tá»« nhiá»u nguá»“n tÃ i liá»‡u uy tÃ­n vÃ  phÃ¢n tÃ­ch báº±ng cÃ´ng nghá»‡ AI. "
                     "CÃ¡c sá»‘ liá»‡u vÃ  thÃ´ng tin Ä‘Æ°á»£c cáº­p nháº­t Ä‘áº¿n thá»i Ä‘iá»ƒm láº­p bÃ¡o cÃ¡o. "
                     "NgÆ°á»i Ä‘á»c nÃªn tham kháº£o thÃªm cÃ¡c nguá»“n chÃ­nh thá»©c Ä‘á»ƒ cÃ³ thÃ´ng tin má»›i nháº¥t.")
    note_para.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
    set_paragraph_font(note_para, font_size=9)
    note_para.runs[0].italic = True
    note_para.runs[1].italic = True

def get_industry_specific_references(topic):
    """Láº¥y tÃ i liá»‡u tham kháº£o theo ngÃ nh"""
    topic_lower = topic.lower()
    
    # Technology/Digital
    if any(keyword in topic_lower for keyword in ['cÃ´ng nghá»‡', 'technology', 'digital', 'ai', 'tech']):
        return [
            "11. Vietnam Software and IT Services Association (VINASA). (2024). Vietnam IT Industry Report.",
            "12. FPT Technology Research Institute. (2024). Digital Transformation in Vietnam.",
            "13. Vietnam National University. (2024). Technology Innovation and Development Studies."
        ]
    
    # Automotive/Electric Vehicles
    elif any(keyword in topic_lower for keyword in ['Ã´ tÃ´', 'xe', 'automotive', 'vehicle', 'electric']):
        return [
            "11. Vietnam Automobile Manufacturers Association (VAMA). (2024). Vietnam Automotive Industry Report.",
            "12. Ministry of Transport Vietnam. (2024). Transport Development Strategy 2021-2030.",
            "13. Vietnam Electric Vehicle Association. (2024). EV Market Development and Policy Framework."
        ]
    
    # Food & Beverage
    elif any(keyword in topic_lower for keyword in ['thá»±c pháº©m', 'food', 'beverage', 'Ä‘á»“ uá»‘ng']):
        return [
            "11. Vietnam Food Association (VFA). (2024). Vietnam Food Industry Development Report.",
            "12. Ministry of Agriculture and Rural Development. (2024). Agricultural Product Export Statistics.",
            "13. Vietnam National Nutrition Institute. (2024). Food Safety and Quality Standards."
        ]
    
    # Real Estate
    elif any(keyword in topic_lower for keyword in ['báº¥t Ä‘á»™ng sáº£n', 'real estate', 'property']):
        return [
            "11. Vietnam Association of Realtors (VARS). (2024). Vietnam Real Estate Market Report.",
            "12. Ministry of Construction. (2024). Housing Development Strategy 2021-2030.",
            "13. CBRE Vietnam. (2024). Vietnam Real Estate Market Outlook."
        ]
    
    # Finance/Banking
    elif any(keyword in topic_lower for keyword in ['tÃ i chÃ­nh', 'ngÃ¢n hÃ ng', 'finance', 'banking']):
        return [
            "11. State Bank of Vietnam. (2024). Monetary Policy and Banking Sector Report.",
            "12. Vietnam Banks Association. (2024). Banking Industry Development Report.",
            "13. International Finance Corporation. (2024). Vietnam Financial Sector Development."
        ]
    
    # Default general business references
    else:
        return [
            "11. Vietnam Institute for Economic and Policy Research (VEPR). (2024). Vietnam Economic Report.",
            "12. Ho Chi Minh City Institute for Development Studies. (2024). Business Environment Analysis.",
            "13. Foreign Investment Agency. (2024). FDI and Market Entry Guidelines."
        ]

def get_market_specific_references(market):
    """Láº¥y tÃ i liá»‡u tham kháº£o theo thá»‹ trÆ°á»ng"""
    market_lower = market.lower()
    
    if 'southeast asia' in market_lower or 'asean' in market_lower:
        return [
            "14. ASEAN Secretariat. (2024). ASEAN Economic Integration Report.",
            "15. Asian Development Bank. (2024). Southeast Asia Development Outlook."
        ]
    elif 'asia-pacific' in market_lower or 'asia pacific' in market_lower:
        return [
            "14. Asia-Pacific Economic Cooperation (APEC). (2024). Regional Economic Outlook.",
            "15. International Monetary Fund. (2024). Asia and Pacific Regional Economic Outlook."
        ]
    else:
        return []

def create_executive_summary(doc, data):
    """Táº¡o Executive Summary theo template 5 pháº§n"""
    print("ğŸ“‹ Táº¡o Executive Summary...")
    
    doc.add_page_break()
    
    # Executive Summary Header
    exec_heading = doc.add_heading('ğŸ“‹ TÃ“M Táº®T ÄIá»€U HÃ€NH (EXECUTIVE SUMMARY)', level=1)
    exec_heading.alignment = WD_ALIGN_PARAGRAPH.CENTER
    set_paragraph_font(exec_heading, font_size=18)
    
    # 1. Má»¥c tiÃªu / Má»¥c Ä‘Ã­ch
    section1_heading = doc.add_heading('1. ğŸ¯ Má»¤C TIÃŠU / Má»¤C ÄÃCH', level=2)
    set_paragraph_font(section1_heading, font_size=14)
    
    purpose_para = doc.add_paragraph()
    purpose_text = data.get('purpose', '')
    if purpose_text:
        # If custom purpose is provided, format it properly
        formatted_purpose = format_purpose_text(purpose_text)
        if not formatted_purpose.endswith('.'):
            formatted_purpose += '.'
        purpose_para.add_run(f"BÃ¡o cÃ¡o nÃ y nháº±m {formatted_purpose}")
    else:
        purpose_para.add_run("BÃ¡o cÃ¡o nÃ y nháº±m:")
        purpose_para.add_run(f"""
â€¢ Hiá»ƒu thá»‹ trÆ°á»ng tá»•ng thá»ƒ: xu hÆ°á»›ng, quy mÃ´, tá»‘c Ä‘á»™ tÄƒng trÆ°á»Ÿng cá»§a ngÃ nh {data.get('industry', 'N/A')} táº¡i {data.get('market', 'N/A')}
â€¢ Biáº¿t Ä‘Æ°á»£c mÃ¬nh Ä‘ang Ä‘á»‹nh nháº£y vÃ o thá»‹ trÆ°á»ng lá»›n hay nhá», cháº­t chá»™i hay Ä‘ang má»Ÿ
â€¢ PhÃ¢n tÃ­ch mÃ´i trÆ°á»ng vÄ© mÃ´ áº£nh hÆ°á»Ÿng Ä‘áº¿n ngÃ nh (chÃ­nh trá»‹, kinh táº¿, cÃ´ng nghá»‡...)
â€¢ DÃ¹ng trÆ°á»›c khi quyáº¿t Ä‘á»‹nh cÃ³ nÃªn vÃ o thá»‹ trÆ°á»ng nÃ y khÃ´ng, hoáº·c Ä‘á»ƒ thuyáº¿t phá»¥c nhÃ  Ä‘áº§u tÆ°""")
    
    purpose_para.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
    set_paragraph_font(purpose_para)
    
    # 2. Pháº¡m vi / Bá»‘i cáº£nh
    section2_heading = doc.add_heading('2. ğŸŒ PHáº M VI / Bá»I Cáº¢NH', level=2)
    set_paragraph_font(section2_heading, font_size=14)
    
    scope_para = doc.add_paragraph()
    stats = calculate_statistics(data)
    scope_para.add_run(f"Táº­p trung vÃ o lÄ©nh vá»±c {data.get('industry', 'N/A')} táº¡i thá»‹ trÆ°á»ng {data.get('market', 'Viá»‡t Nam')} trong nÄƒm {datetime.now().year}, sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p nghiÃªn cá»©u phÃ¢n tÃ­ch Ä‘a táº§ng vá»›i {stats['total_questions']} cÃ¢u há»i nghiÃªn cá»©u, Ã¡p dá»¥ng AI Ä‘á»ƒ thu tháº­p vÃ  phÃ¢n tÃ­ch thÃ´ng tin tá»« nhiá»u nguá»“n khÃ¡c nhau.")
    scope_para.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
    set_paragraph_font(scope_para)
    
    # 3. PhÃ¡t hiá»‡n chÃ­nh
    section3_heading = doc.add_heading('3. ğŸ” PHÃT HIá»†N CHÃNH', level=2)
    set_paragraph_font(section3_heading, font_size=14)
    
    # Extract key insights from research content
    insights = extract_key_insights_for_summary(data)
    
    findings_para = doc.add_paragraph()
    findings_para.add_run("ChÃºng tÃ´i nháº­n tháº¥y ráº±ng:")
    for i, insight in enumerate(insights[:4], 1):  # Top 4 insights for findings
        # Capitalize first letter of insight
        insight_text = insight['insight']
        if insight_text and len(insight_text) > 0:
            insight_text = insight_text[0].upper() + insight_text[1:] if len(insight_text) > 1 else insight_text.upper()
        findings_para.add_run(f"\nâ€¢ {insight_text}")
    
    findings_para.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
    set_paragraph_font(findings_para)
    
    # 4. Äá» xuáº¥t hÃ nh Ä‘á»™ng
    section4_heading = doc.add_heading('4. ğŸš€ Äá»€ XUáº¤T HÃ€NH Äá»˜NG', level=2)
    set_paragraph_font(section4_heading, font_size=14)
    
    action_para = doc.add_paragraph()
    action_para.add_run("ChÃºng tÃ´i Ä‘á» xuáº¥t doanh nghiá»‡p nÃªn:")
    action_para.add_run(f"""
â€¢ Táº­p trung phÃ¡t triá»ƒn cÃ¡c sáº£n pháº©m/dá»‹ch vá»¥ phÃ¹ há»£p vá»›i xu hÆ°á»›ng thá»‹ trÆ°á»ng hiá»‡n táº¡i
â€¢ XÃ¢y dá»±ng chiáº¿n lÆ°á»£c tiáº¿p thá»‹ vÃ  bÃ¡n hÃ ng dá»±a trÃªn insights tá»« nghiÃªn cá»©u
â€¢ Äáº§u tÆ° vÃ o cÃ´ng nghá»‡ vÃ  Ä‘á»•i má»›i Ä‘á»ƒ nÃ¢ng cao nÄƒng lá»±c cáº¡nh tranh
â€¢ TÄƒng cÆ°á»ng há»£p tÃ¡c vá»›i cÃ¡c Ä‘á»‘i tÃ¡c chiáº¿n lÆ°á»£c trong ngÃ nh
â€¢ XÃ¢y dá»±ng há»‡ thá»‘ng theo dÃµi vÃ  Ä‘Ã¡nh giÃ¡ thÆ°á»ng xuyÃªn Ä‘á»ƒ á»©ng phÃ³ vá»›i thay Ä‘á»•i thá»‹ trÆ°á»ng""")
    
    action_para.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
    set_paragraph_font(action_para)
    
    # 5. TÃ¡c Ä‘á»™ng ká»³ vá»ng
    section5_heading = doc.add_heading('5. ğŸ“ˆ TÃC Äá»˜NG Ká»² Vá»ŒNG', level=2)
    set_paragraph_font(section5_heading, font_size=14)
    
    impact_para = doc.add_paragraph()
    impact_para.add_run(f"Äiá»u nÃ y sáº½ dáº«n Ä‘áº¿n viá»‡c nÃ¢ng cao vá»‹ tháº¿ cáº¡nh tranh cá»§a doanh nghiá»‡p trong ngÃ nh {data.get('industry', 'N/A')}, tÄƒng cÆ°á»ng kháº£ nÄƒng thÃ­ch á»©ng vá»›i thay Ä‘á»•i thá»‹ trÆ°á»ng, vÃ  tá»‘i Æ°u hÃ³a hiá»‡u quáº£ kinh doanh. Dá»± kiáº¿n sáº½ cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ kháº£ nÄƒng ra quyáº¿t Ä‘á»‹nh chiáº¿n lÆ°á»£c vÃ  táº¡o ra lá»£i tháº¿ cáº¡nh tranh bá»n vá»¯ng trong mÃ´i trÆ°á»ng kinh doanh nÄƒng Ä‘á»™ng.")
    impact_para.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
    set_paragraph_font(impact_para)
    
    # Footer info
    doc.add_paragraph()
    footer_para = doc.add_paragraph()
    footer_para.add_run('ğŸ“… BÃ¡o cÃ¡o Ä‘Æ°á»£c táº¡o tá»± Ä‘á»™ng bá»Ÿi Market Research Automation System').italic = True
    footer_para.add_run(f'\nâ° NgÃ y táº¡o: {datetime.now().strftime("%d/%m/%Y %H:%M")}')
    footer_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
    set_paragraph_font(footer_para, font_size=9)

def extract_key_insights_for_summary(data):
    """TrÃ­ch xuáº¥t key insights Ä‘á»ƒ táº¡o executive summary pháº§n phÃ¡t hiá»‡n chÃ­nh"""
    insights = []
    
    for layer in data.get('research_results', []):
        layer_name = layer.get('layer_name', '')
        
        for category in layer.get('categories', []):
            category_name = category.get('category_name', '')
            
            for question in category.get('questions', []):
                # Láº¥y tá»« comprehensive report trÆ°á»›c
                layer4_comprehensive = question.get('layer4_comprehensive_report', {})
                if layer4_comprehensive:
                    content = layer4_comprehensive.get('comprehensive_content', '')
                    if content:
                        # Extract key trends and opportunities
                        sentences = content.split('.')
                        for sentence in sentences:
                            if any(keyword in sentence.lower() for keyword in ['xu hÆ°á»›ng', 'cÆ¡ há»™i', 'thÃ¡ch thá»©c', 'tÄƒng trÆ°á»Ÿng', 'phÃ¡t triá»ƒn']):
                                insight = sentence.strip()
                                if len(insight) > 50:  # Only meaningful insights
                                    insights.append({
                                        'category': f"{layer_name} - {category_name}",
                                        'insight': insight[:150] + "..." if len(insight) > 150 else insight
                                    })
                                    break
                # Fallback to layer 3
                elif question.get('layer3_content'):
                    content = question.get('layer3_content', '')
                    sentences = content.split('.')
                    for sentence in sentences:
                        if any(keyword in sentence.lower() for keyword in ['quan trá»ng', 'chÃ­nh', 'Ä‘Ã¡ng chÃº Ã½', 'ná»•i báº­t']):
                            insight = sentence.strip()
                            if len(insight) > 50:
                                insights.append({
                                    'category': f"{layer_name} - {category_name}",
                                    'insight': insight[:120] + "..." if len(insight) > 120 else insight
                                })
                                break
    
    return insights[:6]  # Top 6 insights for summary

def clean_comprehensive_content(content):
    """Remove numbering, section headers, and intro sentences from comprehensive content"""
    if not content:
        return content
    
    # Remove intro sentences like "Äá»ƒ tráº£ lá»i chuyÃªn sÃ¢u cÃ¢u há»i vá»..."
    cleaned_content = re.sub(r'^Äá»ƒ tráº£ lá»i[^,]*,\s*', '', content, flags=re.MULTILINE)
    cleaned_content = re.sub(r'^Äá»ƒ tráº£ lá»i[^.]*\.\s*', '', cleaned_content, flags=re.MULTILINE)
    cleaned_content = re.sub(r'^Nháº±m tráº£ lá»i[^,]*,\s*', '', cleaned_content, flags=re.MULTILINE)
    cleaned_content = re.sub(r'^Nháº±m phÃ¢n tÃ­ch[^,]*,\s*', '', cleaned_content, flags=re.MULTILINE)
    
    # Remove section headers like "ğŸ“Š PHÃ‚N TÃCH HIá»†N TRáº NG:", "âš¡ DRIVERS & IMPACTS:", etc.
    cleaned_content = re.sub(r'\n*[ğŸ“Šâš¡ğŸ“ˆâš ï¸ğŸš€]\s*[A-ZÃÃ€áº¢Ãƒáº Ä‚áº®áº°áº²áº´áº¶Ã‚áº¤áº¦áº¨áºªáº¬ÄÃ‰Ãˆáººáº¼áº¸ÃŠáº¾á»€á»‚á»„á»†ÃÃŒá»ˆÄ¨á»ŠÃ“Ã’á»Ã•á»ŒÃ”á»á»’á»”á»–á»˜Æ á»šá»œá»á» á»¢ÃšÃ™á»¦Å¨á»¤Æ¯á»¨á»ªá»¬á»®á»°Ãá»²á»¶á»¸á»´\s&]+:\s*', '\n\n', cleaned_content)
    
    # Remove numbered sections like "1. SECTION:", "2. ANALYSIS:", etc.
    cleaned_content = re.sub(r'\n*\d+\.\s+[A-ZÃÃ€áº¢Ãƒáº Ä‚áº®áº°áº²áº´áº¶Ã‚áº¤áº¦áº¨áºªáº¬ÄÃ‰Ãˆáººáº¼áº¸ÃŠáº¾á»€á»‚á»„á»†ÃÃŒá»ˆÄ¨á»ŠÃ“Ã’á»Ã•á»ŒÃ”á»á»’á»”á»–á»˜Æ á»šá»œá»á» á»¢ÃšÃ™á»¦Å¨á»¤Æ¯á»¨á»ªá»¬á»®á»°Ãá»²á»¶á»¸á»´\s]+:\s*', '\n\n', cleaned_content)
    
    # Remove **bold headers** at start of lines
    cleaned_content = re.sub(r'\n\*\*[^*]+\*\*\s*\(\d+-\d+\s+tá»«\)\s*\n', '\n\n', cleaned_content)
    
    # Remove intro phrases at the beginning
    intro_patterns = [
        r'^Trong bá»‘i cáº£nh nÃ y,\s*',
        r'^ChÃºng ta cáº§n xem xÃ©t[^.]*\.\s*',
        r'^Viá»‡c phÃ¢n tÃ­ch[^.]*\.\s*'
    ]
    
    for pattern in intro_patterns:
        cleaned_content = re.sub(pattern, '', cleaned_content, flags=re.MULTILINE)
    
    # Clean up extra newlines
    cleaned_content = re.sub(r'\n{3,}', '\n\n', cleaned_content)
    
    # Remove leading/trailing whitespace
    cleaned_content = cleaned_content.strip()
    
    return cleaned_content

def create_comprehensive_word_report(json_file, output_file=None):
    """
    Export layered research results to Word document
    Há»— trá»£ comprehensive Layer 4 reports with enhanced formatting
    """
    
    if not os.path.exists(json_file):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file: {json_file}")
        return None
    
    # Load data
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # Táº¡o output filename náº¿u chÆ°a cÃ³
    if output_file is None:
        base_name = os.path.splitext(json_file)[0]
        output_file = f"{base_name}_comprehensive_report.docx"
    
    # Create document
    doc = Document()
    add_custom_styles(doc)
    
    # ===== TRANG BÃŒA =====
    print("ğŸ“„ Táº¡o trang bÃ¬a...")
    
    title = doc.add_heading('BÃO CÃO NGHIÃŠN Cá»¨U THá»Š TRÆ¯á»œNG', 0)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER
    set_paragraph_font(title, font_size=18)
    
    doc.add_paragraph()
    
    # ThÃ´ng tin cÆ¡ báº£n vá»›i Table
    info_heading = doc.add_heading('ğŸ“Š THÃ”NG TIN Tá»”NG QUAN', level=2)
    info_heading.alignment = WD_ALIGN_PARAGRAPH.CENTER
    set_paragraph_font(info_heading, font_size=14)
    
    create_info_table(doc, data)
    
    doc.add_paragraph()
    
    # Purpose
    if data.get('purpose'):
        purpose_heading = doc.add_heading('ğŸ¯ Má»¤C ÄÃCH NGHIÃŠN Cá»¨U', level=2)
        purpose_heading.alignment = WD_ALIGN_PARAGRAPH.CENTER
        set_paragraph_font(purpose_heading, font_size=14)
        
        purpose_para = doc.add_paragraph(data['purpose'])
        purpose_para.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
        set_paragraph_font(purpose_para)
    
    doc.add_page_break()
    
    # ===== Ná»˜I DUNG CHÃNH =====
    print("ğŸ” Táº¡o ná»™i dung bÃ¡o cÃ¡o chi tiáº¿t...")
    
    results_heading = doc.add_heading('ğŸ“‹ Káº¾T QUáº¢ NGHIÃŠN Cá»¨U CHI TIáº¾T', level=1)
    results_heading.alignment = WD_ALIGN_PARAGRAPH.CENTER
    set_paragraph_font(results_heading, font_size=16)
    
    for layer_idx, layer in enumerate(data.get('research_results', []), 1):
        layer_name = layer.get('layer_name', '')
        
        print(f"  ğŸ”¥ Xá»­ lÃ½ Layer: {layer_name}")
        
        # Layer heading
        layer_heading = doc.add_heading(f"{layer_idx}. {layer_name.upper()}", level=1)
        set_paragraph_font(layer_heading, font_size=16)
        
        for cat_idx, category in enumerate(layer.get('categories', []), 1):
            category_name = category.get('category_name', '')
            
            print(f"    ğŸ“‹ Category: {category_name}")
            
            # Category heading
            category_heading = doc.add_heading(f"{cat_idx}. {category_name}", level=2)
            set_paragraph_font(category_heading, font_size=14)
            
            for q_idx, question in enumerate(category.get('questions', []), 1):
                main_question = question.get('main_question', '')
                
                print(f"      â“ Question: {main_question[:50]}...")
                
                # Main question heading
                question_heading = doc.add_heading(f"{q_idx}. {main_question}", level=3)
                set_paragraph_font(question_heading, font_size=12)
                
                # Layer 3 content (more concise)
                layer3_content = question.get('layer3_content', '')
                if layer3_content:
                    # Clean up and make more concise
                    cleaned_content = layer3_content.strip()
                    
                    layer3_para = doc.add_paragraph()
                    layer3_para.add_run('ğŸ“‹ PHÃ‚N TÃCH Tá»”NG QUAN:').bold = True
                    layer3_para.add_run('\n' + cleaned_content)
                    layer3_para.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
                    set_paragraph_font(layer3_para)
                
                # Layer 4 comprehensive report (Æ°u tiÃªn)
                layer4_comprehensive = question.get('layer4_comprehensive_report', {})
                if layer4_comprehensive:
                    print(f"        ğŸ” CÃ³ comprehensive report")
                    
                    comprehensive_content = layer4_comprehensive.get('comprehensive_content', '')
                    if comprehensive_content:
                        # Clean up content and make more structured
                        cleaned_comp_content = clean_comprehensive_content(comprehensive_content).strip()
                        
                        comp_para = doc.add_paragraph()
                        comp_para.add_run('ğŸ¯ PHÃ‚N TÃCH CHUYÃŠN SÃ‚U:').bold = True
                        comp_para.add_run('\n' + cleaned_comp_content)
                        comp_para.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
                        set_paragraph_font(comp_para)
                    
                    # Timestamp
                    timestamp = layer4_comprehensive.get('enhancement_timestamp', '')
                    if timestamp:
                        time_para = doc.add_paragraph()
                        time_para.add_run(f"â° Cáº­p nháº­t: {timestamp}").italic = True
                        time_para.alignment = WD_ALIGN_PARAGRAPH.RIGHT
                        set_paragraph_font(time_para, font_size=9)
                
                # Layer 4 individual enhancements (fallback)
                elif question.get('layer4_enhancements', {}):
                    layer4_enhancements = question.get('layer4_enhancements', {})
                    print(f"        ğŸ¯ CÃ³ {len(layer4_enhancements)} individual enhancements")
                    
                    layer4_heading = doc.add_paragraph()
                    layer4_heading.add_run('ğŸ¯ PHÃ‚N TÃCH CHI TIáº¾T:').bold = True
                    
                    for sub_question, enhancement_data in layer4_enhancements.items():
                        # Sub-question
                        sub_q_para = doc.add_paragraph()
                        sub_q_para.add_run(f"â€¢ {sub_question}").bold = True
                        set_paragraph_font(sub_q_para)
                        
                        # Enhanced content
                        enhanced_content = enhancement_data.get('enhanced_content', '')
                        if enhanced_content:
                            enh_para = doc.add_paragraph(enhanced_content)
                            enh_para.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
                            enh_para.paragraph_format.left_indent = Inches(0.3)
                            set_paragraph_font(enh_para)
                        
                        # Timestamp
                        timestamp = enhancement_data.get('enhancement_timestamp', '')
                        if timestamp:
                            time_para = doc.add_paragraph()
                            time_para.add_run(f"â° Cáº­p nháº­t: {timestamp}").italic = True
                            time_para.alignment = WD_ALIGN_PARAGRAPH.RIGHT
                            set_paragraph_font(time_para, font_size=9)
    
    # ===== REFERENCES SECTION =====
    create_references_section(doc, data)
    
    # ===== EXECUTIVE SUMMARY =====
    create_executive_summary(doc, data)
    
    # Save document
    print(f"ğŸ’¾ LÆ°u file: {output_file}")
    doc.save(output_file)
    print(f"âœ… ÄÃ£ táº¡o Word document: {output_file}")
    
    return output_file

def calculate_statistics(data):
    """TÃ­nh toÃ¡n thá»‘ng kÃª cho bÃ¡o cÃ¡o"""
    stats = {
        'total_layers': 0,
        'total_categories': 0,
        'total_questions': 0,
        'comprehensive_reports': 0,
        'individual_enhancements': 0
    }
    
    research_results = data.get('research_results', [])
    stats['total_layers'] = len(research_results)
    
    for layer in research_results:
        categories = layer.get('categories', [])
        stats['total_categories'] += len(categories)
        
        for category in categories:
            questions = category.get('questions', [])
            stats['total_questions'] += len(questions)
            
            for question in questions:
                # Count comprehensive reports
                if question.get('layer4_comprehensive_report'):
                    stats['comprehensive_reports'] += 1
                
                # Count individual enhancements
                individual_enhancements = question.get('layer4_enhancements', {})
                stats['individual_enhancements'] += len(individual_enhancements)
    
    return stats

def find_latest_research_file():
    """TÃ¬m file research má»›i nháº¥t trong thÆ° má»¥c output"""
    output_dir = 'output'
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        
    files = []
    for file in os.listdir(output_dir):
        if file.startswith('layer3_research_') and file.endswith('.json'):
            files.append(os.path.join(output_dir, file))
    
    if not files:
        # Fallback: tÃ¬m trong thÆ° má»¥c gá»‘c
        files = [f for f in os.listdir('.') if f.startswith('layer3_research_') and f.endswith('.json')]
        
    if not files:
        return None
    
    # Sáº¯p xáº¿p theo thá»i gian modification
    files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
    return files[0]

def main():
    """Main function"""
    print("ğŸ”¬ COMPREHENSIVE WORD EXPORT TOOL")
    print("="*50)
    
    # Táº¡o thÆ° má»¥c output náº¿u chÆ°a cÃ³
    output_dir = 'output'
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"ğŸ“ ÄÃ£ táº¡o thÆ° má»¥c: {output_dir}")
    
    # TÃ¬m file research
    json_file = find_latest_research_file()
    
    if not json_file:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y file research results!")
        print("ğŸ’¡ HÃ£y cháº¡y Layer 3 research trÆ°á»›c.")
        return
    
    print(f"ğŸ“ Sá»­ dá»¥ng file: {json_file}")
    
    # Táº¡o output filename trong thÆ° má»¥c output
    base_name = os.path.basename(json_file).replace('layer3_research_', '').replace('.json', '')
    output_file = os.path.join(output_dir, f"BÃ¡o_cÃ¡o_nghiÃªn_cá»©u_thá»‹_trÆ°á»ng_{base_name}.docx")
    
    # Export
    result = create_comprehensive_word_report(json_file, output_file)
    
    if result:
        print(f"\nğŸ‰ HOÃ€N THÃ€NH!")
        print(f"ğŸ“„ File Word: {result}")
        print(f"ğŸ’¡ CÃ³ thá»ƒ má»Ÿ file báº±ng: open \"{result}\"")
    else:
        print("âŒ Export tháº¥t báº¡i!")

def format_purpose_text(purpose_text):
    """Format purpose text to ensure proper capitalization for both bullet and dash formats"""
    if not purpose_text:
        return purpose_text
    
    # Split by common delimiters and capitalize each item
    lines = purpose_text.split('\n')
    formatted_lines = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # Handle both bullet (â€¢) and dash (-) formats
        if line.startswith('â€¢') or line.startswith('-'):
            # Extract the text after the bullet/dash
            prefix = line[0]  # â€¢ or -
            text = line[1:].strip()
            if text:
                # Capitalize first letter
                text = text[0].upper() + text[1:] if len(text) > 1 else text.upper()
                formatted_lines.append(f"{prefix} {text}")
        else:
            # Regular text - capitalize first letter
            if line:
                line = line[0].upper() + line[1:] if len(line) > 1 else line.upper()
                formatted_lines.append(line)
    
    return '\n'.join(formatted_lines)

if __name__ == "__main__":
    main() 