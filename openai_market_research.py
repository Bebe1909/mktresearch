#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script gá»­i request tá»›i OpenAI GPT API Ä‘á»ƒ nghiÃªn cá»©u thá»‹ trÆ°á»ng
TÃ¡c giáº£: AI Assistant
NgÃ y: 2024
"""

import json
import requests
import time
from typing import Dict, List, Any
import openai

class OpenAIMarketResearch:
    def __init__(self, api_key: str, industry: str = "Technology", market: str = "Viá»‡t Nam", model: str = "gpt-3.5-turbo"):
        """
        Khá»Ÿi táº¡o class nghiÃªn cá»©u thá»‹ trÆ°á»ng vá»›i OpenAI GPT
        
        Args:
            api_key (str): API key cá»§a OpenAI
            industry (str): NgÃ nh cÃ´ng nghiá»‡p nghiÃªn cá»©u
            market (str): Thá»‹ trÆ°á»ng nghiÃªn cá»©u
            model (str): Model GPT sá»­ dá»¥ng
        """
        self.client = openai.OpenAI(api_key=api_key)
        self.industry = industry
        self.market = market
        self.model = model
        self.base_url = "https://api.openai.com/v1/chat/completions"
        self.delay_seconds = 3  # Increased delay from 1 to 3 seconds
        
        # Reference tracking system
        self.reference_tracker = {}
        self.tracked_sources = set()
        
        print(f"ğŸ¤– Initialized OpenAI Market Research for {industry} in {market}")
        print(f"ğŸ“Š API Provider: OpenAI")
        print(f"ğŸ”§ Model: {model}")
        
    def call_openai_api(self, prompt: str, max_retries: int = 3) -> str:
        """Gá»­i request tá»›i OpenAI API vá»›i retry logic vÃ  track references"""
        
        for attempt in range(max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    max_tokens=2000,
                    temperature=0.7
                )
                
                if response.choices and response.choices[0].message:
                    content = response.choices[0].message.content
                    
                    # Track references from the response
                    self.track_references_from_response(content)
                    
                    return content
                else:
                    return "KhÃ´ng cÃ³ ná»™i dung trong pháº£n há»“i API"
                    
            except Exception as e:
                if "429" in str(e) or "rate_limit" in str(e).lower():  # Rate limit error
                    wait_time = (2 ** attempt) * 5  # Exponential backoff: 5, 10, 20 seconds
                    print(f"âš ï¸ Rate limit hit - Waiting {wait_time}s before retry {attempt + 1}/{max_retries}")
                    time.sleep(wait_time)
                    if attempt == max_retries - 1:
                        print(f"âŒ Max retries reached. Error: {e}")
                        return f"Rate limit error after {max_retries} retries: {e}"
                else:
                    print(f"âŒ API Error: {e}")
                    return f"API Error: {e}"
        
        return "Failed after all retries"
    
    def track_references_from_response(self, content: str):
        """Extract and track references from AI response"""
        import re
        
        # Patterns to detect references and sources in AI responses
        reference_patterns = [
            # Organizations and institutions
            r'\b(?:Tá»•ng cá»¥c Thá»‘ng kÃª|General Statistics Office|GSO)\b',
            r'\b(?:NgÃ¢n hÃ ng Tháº¿ giá»›i|World Bank)\b',
            r'\b(?:IMF|International Monetary Fund)\b',
            r'\b(?:ADB|Asian Development Bank)\b',
            r'\b(?:McKinsey|Deloitte|PwC|KPMG|BCG)\b',
            r'\b(?:Nielsen|Euromonitor|Statista)\b',
            r'\b(?:VCCI|Vietnam Chamber of Commerce)\b',
            r'\b(?:Bá»™ (?:Káº¿ hoáº¡ch|TÃ i chÃ­nh|CÃ´ng ThÆ°Æ¡ng|Y táº¿|GiÃ¡o dá»¥c))\b',
            
            # Vietnam specific
            r'\b(?:VAMA|Vietnam Automobile)\b',
            r'\b(?:VINASA|Vietnam Software)\b',
            r'\b(?:VFA|Vietnam Food Association)\b',
            r'\b(?:FPT|Viettel|VNPT)\b',
            r'\b(?:NgÃ¢n hÃ ng NhÃ  nÆ°á»›c|State Bank of Vietnam)\b',
            
            # Global sources
            r'\b(?:Bloomberg|Reuters|Financial Times)\b',
            r'\b(?:Forbes|Harvard Business Review|MIT)\b',
            r'\b(?:Gartner|IDC|Forrester)\b',
            
            # Government and regulatory
            r'\b(?:Ministry of|Bá»™)\s+[A-Za-zÃ€-á»¹\s]+\b',
            r'\b(?:Government of|ChÃ­nh phá»§)\s+[A-Za-zÃ€-á»¹\s]+\b',
        ]
        
        # Extract references
        for pattern in reference_patterns:
            matches = re.finditer(pattern, content, re.IGNORECASE)
            for match in matches:
                source = match.group().strip()
                if source and len(source) > 3:  # Avoid very short matches
                    # Normalize source name
                    normalized_source = self.normalize_source_name(source)
                    
                    # Track frequency
                    if normalized_source in self.reference_tracker:
                        self.reference_tracker[normalized_source] += 1
                    else:
                        self.reference_tracker[normalized_source] = 1
                    
                    self.tracked_sources.add(normalized_source)
    
    def normalize_source_name(self, source: str) -> str:
        """Normalize source names for consistent tracking"""
        source = source.strip()
        
        # Mapping for common variations
        mappings = {
            'Tá»•ng cá»¥c Thá»‘ng kÃª': 'General Statistics Office (GSO)',
            'General Statistics Office': 'General Statistics Office (GSO)',
            'GSO': 'General Statistics Office (GSO)',
            'NgÃ¢n hÃ ng Tháº¿ giá»›i': 'World Bank',
            'World Bank': 'World Bank',
            'IMF': 'International Monetary Fund (IMF)',
            'International Monetary Fund': 'International Monetary Fund (IMF)',
            'McKinsey': 'McKinsey & Company',
            'Deloitte': 'Deloitte Consulting',
            'PwC': 'PricewaterhouseCoopers (PwC)',
            'KPMG': 'KPMG International',
            'Nielsen': 'Nielsen Holdings',
            'Euromonitor': 'Euromonitor International',
            'Statista': 'Statista GmbH',
            'VCCI': 'Vietnam Chamber of Commerce and Industry (VCCI)',
            'Vietnam Chamber of Commerce': 'Vietnam Chamber of Commerce and Industry (VCCI)',
        }
        
        return mappings.get(source, source)
    
    def get_top_references(self, limit: int = 10) -> list:
        """Get top references sorted by frequency"""
        sorted_refs = sorted(
            self.reference_tracker.items(), 
            key=lambda x: x[1], 
            reverse=True
        )
        return sorted_refs[:limit]

    def create_layer3_prompt_request(self, layer1: str, layer2: str, main_question: str, purpose: str) -> str:
        """Táº¡o request Ä‘á»ƒ láº¥y prompt Layer 3 (main question level) - DIRECT ANSWER FOCUSED"""
        template = f'''Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch thá»‹ trÆ°á»ng cho ngÃ nh "{self.industry}" táº¡i thá»‹ trÆ°á»ng "{self.market}".

Má»¤C ÄÃCH NGHIÃŠN Cá»¨U: {purpose}

NGá»® Cáº¢NH PHÃ‚N TÃCH:
- Chá»§ Ä‘á» chÃ­nh: {layer1}
- LÄ©nh vá»±c: {layer2}

CÃ‚U Há»I Cáº¦N TRáº¢ Lá»œI: "{main_question}"

ğŸ¯ **YÃŠU Cáº¦U Báº®T BUá»˜C:**
1. **TRáº¢ Lá»œI TRá»°C TIáº¾P** cÃ¢u há»i ngay tá»« cÃ¢u Ä‘áº§u tiÃªn
2. **Báº®T Äáº¦U** báº±ng: "Äá»ƒ tráº£ lá»i cÃ¢u há»i vá» [tÃ³m táº¯t ngáº¯n cÃ¢u há»i]..."
3. **FOCUS 100%** vÃ o ná»™i dung mÃ  cÃ¢u há»i Ä‘ang há»i - khÃ´ng drift sang chá»§ Ä‘á» khÃ¡c
4. **Sá»¬ Dá»¤NG** sá»‘ liá»‡u vÃ  vÃ­ dá»¥ cá»¥ thá»ƒ tá»« thá»‹ trÆ°á»ng {self.market}
5. **Káº¾T THÃšC** báº±ng conclusion tráº£ lá»i rÃµ rÃ ng cÃ¢u há»i

**Cáº¤U TRÃšC:**
- Äoáº¡n 1: Tráº£ lá»i trá»±c tiáº¿p + evidence chÃ­nh (3-4 cÃ¢u)
- Äoáº¡n 2: PhÃ¢n tÃ­ch deeper vá»›i data/examples (3-4 cÃ¢u)  
- Äoáº¡n 3: Impact/implications vÃ  conclusion (2-3 cÃ¢u)

**TRÃNH:**
- NÃ³i chung chung hoáº·c láº¡c Ä‘á»
- Äáº·t cÃ¢u há»i thÃªm
- PhÃ¢n tÃ­ch nhá»¯ng gÃ¬ khÃ´ng Ä‘Æ°á»£c há»i

**CHá»ˆ Táº¬P TRUNG:** Tráº£ lá»i chÃ­nh xÃ¡c vÃ  Ä‘áº§y Ä‘á»§ cÃ¢u há»i "{main_question}"'''
        
        return template

    def create_layer3_comprehensive_category_prompt(self, layer1: str, layer2: str, all_questions: list, purpose: str) -> str:
        """Táº¡o prompt Ä‘á»ƒ phÃ¢n tÃ­ch comprehensive cho toÃ n bá»™ category (Layer 3 mode)"""
        
        # Get Vietnamese market name for Vietnamese reports
        vietnamese_market = self.get_vietnamese_market_name(self.market)
        
        questions_text = "\n".join([f"- {q}" for q in all_questions])
        
        template = f'''Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch thá»‹ trÆ°á»ng cho ngÃ nh "{self.industry}" táº¡i thá»‹ trÆ°á»ng "{vietnamese_market}".

NGá»® Cáº¢NH: {layer1} > {layer2}
Má»¤C ÄÃCH NGHIÃŠN Cá»¨U: "{purpose}"

CÃC CÃ‚U Há»I Cáº¦N TRáº¢ Lá»œI TOÃ€N DIá»†N:
{questions_text}

ğŸ¯ **NHIá»†M Vá»¤:** Viáº¿t phÃ¢n tÃ­ch comprehensive cho toÃ n bá»™ category "{layer2}" báº±ng cÃ¡ch tráº£ lá»i tÃ­ch há»£p Táº¤T Cáº¢ cÃ¢u há»i trÃªn.

**Báº®T Äáº¦U NGAY Vá»šI PHÃ‚N TÃCH** - KHÃ”NG cÃ³ cÃ¢u giá»›i thiá»‡u hay má»Ÿ Ä‘áº§u, Ä‘i tháº³ng vÃ o tÃ¬nh hÃ¬nh hiá»‡n táº¡i.

**CÃCH VIáº¾T - FLOW Tá»° NHIÃŠN:**

Viáº¿t má»™t phÃ¢n tÃ­ch dáº¡ng vÄƒn xuÃ´i, liá»n máº¡ch theo logic:
1. **TÃ¬nh hÃ¬nh hiá»‡n táº¡i** (150-200 tá»«): Báº¯t Ä‘áº§u ngay vá»›i overview vá» {layer2} trong ngÃ nh {self.industry}
2. **PhÃ¢n tÃ­ch chi tiáº¿t** (200-250 tá»«): Deep dive cÃ¡c factors chÃ­nh, data cá»¥ thá»ƒ 
3. **TÃ¡c Ä‘á»™ng vÃ  xu hÆ°á»›ng** (150-200 tá»«): Impacts, trends, opportunities 
4. **Khuyáº¿n nghá»‹ chiáº¿n lÆ°á»£c** (100-150 tá»«): Actionable insights vÃ  recommendations

**YÃŠU Cáº¦U:**
- Báº®T Äáº¦U NGAY vá»›i phÃ¢n tÃ­ch (VD: "TÃ¬nh hÃ¬nh {layer2} hiá»‡n táº¡i...", "Trong bá»‘i cáº£nh {layer2}...")
- TRáº¢ Lá»œI Háº¾T Táº¤T Cáº¢ cÃ¡c cÃ¢u há»i Ä‘Æ°á»£c liá»‡t kÃª
- VIáº¾T liá»n máº¡ch nhÆ° má»™t bÃ i phÃ¢n tÃ­ch chuyÃªn nghiá»‡p
- Sá»¬ Dá»¤NG data vÃ  examples cá»¥ thá»ƒ tá»« {vietnamese_market}
- TRÃNH section headers, viáº¿t dáº¡ng essay flow tá»± nhiÃªn
- Káº¾T Há»¢P insights tá»« táº¥t cáº£ cÃ¢u há»i thÃ nh má»™t comprehensive view

**PHONG CÃCH:**
- Professional analysis writing
- Smooth transitions giá»¯a cÃ¡c Ã½
- Evidence-based vá»›i concrete examples
- Forward-looking perspective

**VÃ Dá»¤ Báº®T Äáº¦U Tá»T:**
"TÃ¬nh hÃ¬nh {layer2} trong ngÃ nh {self.industry} táº¡i {vietnamese_market} hiá»‡n Ä‘ang..."
"Bá»‘i cáº£nh {layer2} cho tháº¥y..."
"MÃ´i trÆ°á»ng {layer2} Ä‘ang tráº£i qua..."

Táº¡o má»™t phÃ¢n tÃ­ch comprehensive tráº£ lá»i háº¿t cÃ¡c cÃ¢u há»i trÃªn Ä‘á»ƒ hiá»ƒu toÃ n diá»‡n vá» {layer2} impact lÃªn ngÃ nh {self.industry}.'''
        
        return template

    def create_layer4_enhancement_prompt(self, layer1: str, layer2: str, main_question: str, sub_question: str, layer3_content: str, purpose: str) -> str:
        """Táº¡o prompt Ä‘á»ƒ enhance specific section tá»« Layer 3 lÃªn Layer 4"""
        template = f'''As a master prompt engineer, I need to enhance a specific section of an existing market research report from Layer 3 to Layer 4 standard for: "{self.industry}" in market: "{self.market}". 

The research purpose is: "{purpose}"
Structure: layer 1: {layer1} | layer 2: {layer2} | layer 3: {main_question}

EXISTING LAYER 3 CONTENT TO ENHANCE:
{layer3_content}

SPECIFIC ENHANCEMENT REQUEST (Layer 4):
{sub_question}

Create a prompt for GPT to provide deep, detailed analysis specifically for the enhancement request above, while building upon the existing Layer 3 content. The result should be much more detailed, with specific data, examples, and actionable insights. Vietnamese answer only.'''
        
        return template

    def create_layer4_comprehensive_report_prompt(self, layer1: str, layer2: str, main_question: str, sub_questions: list, layer3_content: str, purpose: str) -> str:
        """Táº¡o prompt Ä‘á»ƒ táº¡o bÃ¡o cÃ¡o Layer 4 tá»•ng há»£p - DIRECT CONTENT, NO INTRO"""
        
        # Get Vietnamese market name for Vietnamese reports
        vietnamese_market = self.get_vietnamese_market_name(self.market)
        
        sub_questions_text = "\n".join([f"- {sq}" for sq in sub_questions])
        
        template = f'''Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch thá»‹ trÆ°á»ng cho ngÃ nh "{self.industry}" táº¡i thá»‹ trÆ°á»ng "{vietnamese_market}".

NGá»® Cáº¢NH: {layer1} > {layer2}
CÃ‚U Há»I CHÃNH Cáº¦N TRáº¢ Lá»œI: "{main_question}"

PHÃ‚N TÃCH Sáº´N CÃ“ (Layer 3):
{layer3_content}

CÃC KHÃA Cáº NH CHI TIáº¾T Cáº¦N PHÃ‚N TÃCH:
{sub_questions_text}

ğŸ¯ **NHIá»†M Vá»¤:** Viáº¿t phÃ¢n tÃ­ch chuyÃªn sÃ¢u tráº£ lá»i cÃ¢u há»i chÃ­nh "{main_question}" báº±ng cÃ¡ch tÃ­ch há»£p táº¥t cáº£ khÃ­a cáº¡nh chi tiáº¿t.

**Báº®T Äáº¦U NGAY Vá»šI Ná»˜I DUNG PHÃ‚N TÃCH** - KHÃ”NG cÃ³ cÃ¢u giá»›i thiá»‡u, khÃ´ng cÃ³ "Äá»ƒ tráº£ lá»i cÃ¢u há»i...", Ä‘i tháº³ng vÃ o tÃ¬nh hÃ¬nh hiá»‡n táº¡i.

**CÃCH VIáº¾T - FLOW Tá»° NHIÃŠN:**

Viáº¿t má»™t phÃ¢n tÃ­ch dáº¡ng vÄƒn xuÃ´i, liá»n máº¡ch theo logic:
1. **TÃ¬nh hÃ¬nh hiá»‡n táº¡i** (120-150 tá»«): Báº¯t Ä‘áº§u ngay vá»›i phÃ¢n tÃ­ch tÃ¬nh tráº¡ng hiá»‡n táº¡i, data cá»¥ thá»ƒ
2. **Äá»™ng lá»±c vÃ  tÃ¡c Ä‘á»™ng** (120-150 tá»«): Drivers chÃ­nh, impacts lÃªn players vÃ  consumers
3. **CÆ¡ há»™i vÃ  xu hÆ°á»›ng** (120-150 tá»«): Opportunities, growth areas, success cases
4. **ThÃ¡ch thá»©c vÃ  rá»§i ro** (80-120 tá»«): Barriers, risks cáº§n monitor
5. **Khuyáº¿n nghá»‹ chiáº¿n lÆ°á»£c** (100-120 tá»«): Actionable steps cá»¥ thá»ƒ

**YÃŠU Cáº¦U CRITICAL:**
- Báº®T Äáº¦U NGAY báº±ng cÃ¢u vá» tÃ¬nh hÃ¬nh thá»±c táº¿ (VD: "Hiá»‡n táº¡i thá»‹ trÆ°á»ng...", "Trong bá»‘i cáº£nh...", "TÃ¬nh tráº¡ng hiá»‡n táº¡i...")
- KHÃ”NG sá»­ dá»¥ng section headers hay bullet points
- KHÃ”NG cÃ³ cÃ¢u giá»›i thiá»‡u hay má»Ÿ Ä‘áº§u
- VIáº¾T liá»n máº¡ch nhÆ° má»™t bÃ i phÃ¢n tÃ­ch chuyÃªn nghiá»‡p
- Use real {vietnamese_market} market data vÃ  case studies
- BE SPECIFIC - trÃ¡nh generalities
- Total: 550-700 tá»«

**PHONG CÃCH:**
- VÄƒn xuÃ´i professional, máº¡ch láº¡c
- Transition tá»± nhiÃªn giá»¯a cÃ¡c Ã½
- Báº¯t Ä‘áº§u ngay vá»›i facts vÃ  analysis
- Flow nhÆ° má»™t essay analysis, khÃ´ng intro

**VÃ Dá»¤ Báº®T Äáº¦U Tá»T:**
"Hiá»‡n táº¡i ngÃ nh [X] Ä‘ang tráº£i qua..."
"Trong bá»‘i cáº£nh thá»‹ trÆ°á»ng [Y]..."
"TÃ¬nh tráº¡ng hiá»‡n táº¡i cho tháº¥y..."
"Thá»‹ trÆ°á»ng [Z] Ä‘ang chá»©ng kiáº¿n..."

**Káº¾T THÃšC** vá»›i conclusion tráº£ lá»i hoÃ n chá»‰nh cÃ¢u há»i chÃ­nh.'''
        
        return template

    def process_layer3_research(self, json_file: str = "market_research_structured.json", limit: int = None) -> Dict[str, Any]:
        """
        Xá»­ lÃ½ nghiÃªn cá»©u thá»‹ trÆ°á»ng á»Ÿ Layer 3 standard (main questions only)
        
        Args:
            json_file (str): ÄÆ°á»ng dáº«n file JSON chá»©a dá»¯ liá»‡u
            limit (int): Giá»›i háº¡n sá»‘ questions Ä‘á»ƒ test (None = unlimited)
            
        Returns:
            Dict: Káº¿t quáº£ nghiÃªn cá»©u thá»‹ trÆ°á»ng Layer 3
        """
        
        # Äá»c file JSON
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        purpose = data.get('purpose', '')
        layers = data.get('layers', [])
        
        results = {
            "industry": self.industry,
            "market": self.market,
            "purpose": purpose,
            "research_standard": "Layer 3",
            "api_provider": "openai",
            "model_used": self.model,
            "research_results": []
        }
        
        total_questions = 0
        processed_questions = 0
        
        # Äáº¿m tá»•ng sá»‘ main questions (Layer 3)
        for layer in layers:
            for category in layer.get('categories', []):
                total_questions += len(category.get('questions', []))
        
        # Apply limit if specified
        if limit:
            total_questions = min(total_questions, limit)
            print(f"ğŸš§ Testing mode: Giá»›i háº¡n {limit} questions")
        
        print(f"ğŸ¯ Báº¯t Ä‘áº§u nghiÃªn cá»©u thá»‹ trÆ°á»ng Layer 3: {self.industry}")
        print(f"ğŸ“Š Thá»‹ trÆ°á»ng: {self.market}")
        print(f"ğŸ¤– API: OpenAI {self.model}")
        print(f"â“ Tá»•ng sá»‘ main questions (Layer 3): {total_questions}")
        print("="*60)
        
        for layer in layers:
            layer_name = layer.get('name', '')
            layer_result = {
                "layer_name": layer_name,
                "categories": []
            }
            
            print(f"\nğŸ”¥ Äang xá»­ lÃ½ Layer: {layer_name}")
            
            for category in layer.get('categories', []):
                category_name = category.get('name', '')
                category_result = {
                    "category_name": category_name,
                    "questions": []
                }
                
                print(f"ğŸ“‹ Category: {category_name}")
                
                for question in category.get('questions', []):
                    # Check limit
                    if limit and processed_questions >= limit:
                        print(f"ğŸš§ ÄÃ£ Ä‘áº¡t giá»›i háº¡n {limit} questions, dá»«ng láº¡i.")
                        break
                        
                    main_question = question.get('main_question', '')
                    processed_questions += 1
                    progress = (processed_questions / total_questions) * 100
                    
                    print(f"  â“ [{processed_questions}/{total_questions}] ({progress:.1f}%) Processing: {main_question[:50]}...")
                    
                    # BÆ°á»›c 1: Táº¡o Layer 3 prompt request
                    prompt_request = self.create_layer3_prompt_request(
                        layer_name, category_name, main_question, purpose
                    )
                    
                    # BÆ°á»›c 2: Gá»­i request Ä‘á»ƒ láº¥y prompt
                    print(f"    ğŸ”„ Táº¡o Layer 3 prompt...")
                    generated_prompt = self.call_openai_api(prompt_request)
                    
                    # BÆ°á»›c 3: Sá»­ dá»¥ng prompt Ä‘á»ƒ láº¥y káº¿t quáº£ Layer 3
                    print(f"    ğŸ” NghiÃªn cá»©u Layer 3...")
                    research_result = self.call_openai_api(generated_prompt)
                    
                    # LÆ°u káº¿t quáº£ vá»›i cáº¥u trÃºc má»›i cho Layer 3
                    question_result = {
                        "main_question": main_question,
                        "research_standard": "Layer 3",
                        "generated_prompt": generated_prompt,
                        "layer3_content": research_result,
                        "sub_questions": question.get('sub_questions', []),  # LÆ°u Ä‘á»ƒ cÃ³ thá»ƒ enhance sau
                        "layer4_enhancements": {}  # Dict Ä‘á»ƒ lÆ°u cÃ¡c enhancement
                    }
                    
                    category_result["questions"].append(question_result)
                    
                    # Delay Ä‘á»ƒ trÃ¡nh rate limit
                    time.sleep(self.delay_seconds)
                    
                    print(f"    âœ… HoÃ n thÃ nh Layer 3!")
                
                if category_result["questions"]:  # Only add if has questions
                    layer_result["categories"].append(category_result)
                    
                # Check limit
                if limit and processed_questions >= limit:
                    break
            
            if layer_result["categories"]:  # Only add if has categories
                results["research_results"].append(layer_result)
                
            # Check limit
            if limit and processed_questions >= limit:
                break
        
        print("\n" + "="*60)
        print(f"ğŸ‰ HoÃ n thÃ nh nghiÃªn cá»©u thá»‹ trÆ°á»ng Layer 3!")
        print(f"ğŸ“Š ÄÃ£ xá»­ lÃ½: {processed_questions} main questions")
        
        return results

    def enhance_to_layer4(self, layer3_results: Dict[str, Any], layer_name: str, category_name: str, main_question: str, sub_question: str) -> str:
        """
        Enhance má»™t section cá»¥ thá»ƒ tá»« Layer 3 lÃªn Layer 4
        """
        
        # TÃ¬m layer3_content tÆ°Æ¡ng á»©ng
        layer3_content = ""
        purpose = layer3_results.get('purpose', '')
        
        for layer in layer3_results.get('research_results', []):
            if layer.get('layer_name') == layer_name:
                for category in layer.get('categories', []):
                    if category.get('category_name') == category_name:
                        for question in category.get('questions', []):
                            if question.get('main_question') == main_question:
                                layer3_content = question.get('layer3_content', '')
                                break
        
        if not layer3_content:
            return "KhÃ´ng tÃ¬m tháº¥y ná»™i dung Layer 3 Ä‘á»ƒ enhance"
        
        print(f"ğŸ”„ Enhancing to Layer 4: {sub_question[:50]}...")
        
        # BÆ°á»›c 1: Táº¡o enhancement prompt
        enhancement_prompt_request = self.create_layer4_enhancement_prompt(
            layer_name, category_name, main_question, sub_question, layer3_content, purpose
        )
        
        # BÆ°á»›c 2: Láº¥y enhancement prompt
        print(f"    ğŸ”„ Táº¡o Layer 4 enhancement prompt...")
        generated_prompt = self.call_openai_api(enhancement_prompt_request)
        
        # BÆ°á»›c 3: Cháº¡y enhancement
        print(f"    ğŸ” Thá»±c hiá»‡n Layer 4 enhancement...")
        enhancement_result = self.call_openai_api(generated_prompt)
        
        print(f"    âœ… HoÃ n thÃ nh Layer 4 enhancement!")
        
        return enhancement_result

    def enhance_to_layer4_comprehensive(self, layer3_results: Dict[str, Any], layer_name: str, category_name: str, main_question: str) -> str:
        """
        Táº¡o bÃ¡o cÃ¡o Layer 4 tá»•ng há»£p cho toÃ n bá»™ main question (táº¥t cáº£ sub-questions)
        """
        
        # TÃ¬m layer3_content vÃ  sub_questions tÆ°Æ¡ng á»©ng
        layer3_content = ""
        sub_questions = []
        purpose = layer3_results.get('purpose', '')
        
        for layer in layer3_results.get('research_results', []):
            if layer.get('layer_name') == layer_name:
                for category in layer.get('categories', []):
                    if category.get('category_name') == category_name:
                        for question in category.get('questions', []):
                            if question.get('main_question') == main_question:
                                layer3_content = question.get('layer3_content', '')
                                sub_questions = question.get('sub_questions', [])
                                break
        
        if not layer3_content:
            return "KhÃ´ng tÃ¬m tháº¥y ná»™i dung Layer 3 Ä‘á»ƒ enhance"
        
        if not sub_questions:
            return "KhÃ´ng tÃ¬m tháº¥y sub-questions Ä‘á»ƒ táº¡o bÃ¡o cÃ¡o tá»•ng há»£p"
        
        print(f"ğŸ”„ Táº¡o bÃ¡o cÃ¡o Layer 4 tá»•ng há»£p vá»›i {len(sub_questions)} sub-questions...")
        
        # Táº¡o comprehensive report prompt
        comprehensive_prompt = self.create_layer4_comprehensive_report_prompt(
            layer_name, category_name, main_question, sub_questions, layer3_content, purpose
        )
        
        # Gá»i API Ä‘á»ƒ táº¡o comprehensive report
        print(f"    ğŸ” Thá»±c hiá»‡n Layer 4 comprehensive analysis...")
        comprehensive_report = self.call_openai_api(comprehensive_prompt)
        
        print(f"    âœ… HoÃ n thÃ nh Layer 4 comprehensive report!")
        
        return comprehensive_report

    def add_layer4_enhancement(self, results_file: str, layer_name: str, category_name: str, main_question: str, sub_question: str, output_file: str = None) -> str:
        """
        ThÃªm Layer 4 enhancement vÃ o káº¿t quáº£ hiá»‡n cÃ³ vÃ  lÆ°u file
        """
        
        # Äá»c káº¿t quáº£ hiá»‡n cÃ³
        with open(results_file, 'r', encoding='utf-8') as f:
            results = json.load(f)
        
        # Thá»±c hiá»‡n enhancement
        enhancement_content = self.enhance_to_layer4(results, layer_name, category_name, main_question, sub_question)
        
        # Cáº­p nháº­t káº¿t quáº£
        for layer in results.get('research_results', []):
            if layer.get('layer_name') == layer_name:
                for category in layer.get('categories', []):
                    if category.get('category_name') == category_name:
                        for question in category.get('questions', []):
                            if question.get('main_question') == main_question:
                                # ThÃªm enhancement vÃ o dict
                                question['layer4_enhancements'][sub_question] = {
                                    "enhanced_content": enhancement_content,
                                    "enhancement_timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                                }
                                break
        
        # LÆ°u file
        if output_file is None:
            output_file = results_file  # Ghi Ä‘Ã¨ file gá»‘c
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ÄÃ£ cáº­p nháº­t Layer 4 enhancement vÃ o: {output_file}")
        return output_file

    def add_layer4_comprehensive_enhancement(self, results_file: str, layer_name: str, category_name: str, main_question: str, output_file: str = None) -> str:
        """
        ThÃªm Layer 4 comprehensive enhancement vÃ o káº¿t quáº£ hiá»‡n cÃ³ vÃ  lÆ°u file
        """
        
        # Äá»c káº¿t quáº£ hiá»‡n cÃ³
        with open(results_file, 'r', encoding='utf-8') as f:
            results = json.load(f)
        
        # Thá»±c hiá»‡n comprehensive enhancement
        comprehensive_content = self.enhance_to_layer4_comprehensive(results, layer_name, category_name, main_question)
        
        # Cáº­p nháº­t káº¿t quáº£ vá»›i comprehensive report
        for layer in results.get('research_results', []):
            if layer.get('layer_name') == layer_name:
                for category in layer.get('categories', []):
                    if category.get('category_name') == category_name:
                        for question in category.get('questions', []):
                            if question.get('main_question') == main_question:
                                # ThÃªm comprehensive enhancement
                                question['layer4_comprehensive_report'] = {
                                    "comprehensive_content": comprehensive_content,
                                    "enhancement_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                                    "sub_questions_integrated": question.get('sub_questions', [])
                                }
                                break
        
        # LÆ°u file
        if output_file is None:
            output_file = results_file  # Ghi Ä‘Ã¨ file gá»‘c
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ÄÃ£ cáº­p nháº­t Layer 4 comprehensive report vÃ o: {output_file}")
        return output_file

    def run_layer3_research(self, structured_data: dict, topic: str, testing_mode: bool = False, analysis_level: str = "Layer 4 Analysis") -> dict:
        """Main research execution with comprehensive error handling and reference tracking"""
        
        print(f"ğŸ¯ Báº¯t Ä‘áº§u nghiÃªn cá»©u thá»‹ trÆ°á»ng Layer 3: {topic}")
        print(f"ğŸ“Š Thá»‹ trÆ°á»ng: {self.market}")
        print(f"ğŸ¤– API: OpenAI {self.model}")
        print(f"ğŸ”¬ Analysis Level: {analysis_level}")
        
        # Reset reference tracking for new research
        self.reference_tracker = {}
        self.tracked_sources = set()
        
        # Get purpose from structured data
        purpose = structured_data.get('purpose', 'NghiÃªn cá»©u thá»‹ trÆ°á»ng vÃ  phÃ¢n tÃ­ch cÆ¡ há»™i kinh doanh')
        
        # Create result structure
        result = {
            'research_metadata': {
                'industry': topic,
                'market': self.market,
                'model_used': self.model,
                'api_provider': 'OpenAI',
                'purpose': purpose,
                'analysis_level': analysis_level,
                'research_timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
                'testing_mode': testing_mode
            },
            'research_results': [],
            'research_statistics': {},
            'tracked_references': []  # Will be populated at the end
        }
        
        # Count total questions for progress tracking
        total_questions = 0
        total_questions_available = 0
        
        # First pass: count all available questions
        for layer in structured_data.get('layers', []):
            for category in layer.get('categories', []):
                questions = category.get('questions', [])
                total_questions_available += len(questions)
        
        if testing_mode:
            total_questions = min(5, total_questions_available)  # Limit to exactly 5 questions
            print(f"ğŸ§ª Testing mode: Limiting to {total_questions} questions out of {total_questions_available} available")
        else:
            total_questions = total_questions_available
        
        print(f"â“ Tá»•ng sá»‘ main questions (Layer 3): {total_questions}")
        print("=" * 60)
        
        processed_questions = 0
        
        # Branch logic based on analysis level
        if analysis_level == "Layer 3 Analysis":
            return self._run_layer3_category_analysis(structured_data, purpose, result, testing_mode)
        else:
            return self._run_layer4_detailed_analysis(structured_data, purpose, result, testing_mode)
    
    def _run_layer3_category_analysis(self, structured_data: dict, purpose: str, result: dict, testing_mode: bool) -> dict:
        """Layer 3 Analysis Mode: Comprehensive analysis per category"""
        
        print("ğŸ¯ Cháº¿ Ä‘á»™ Layer 3: PhÃ¢n tÃ­ch comprehensive theo category")
        processed_categories = 0
        total_questions_processed = 0
        
        for layer in structured_data.get('layers', []):
            layer_name = layer.get('name', '')
            layer_result = {
                'layer_name': layer_name,
                'categories': []
            }
            
            print(f"ğŸ”¥ Äang xá»­ lÃ½ Layer: {layer_name}")
            
            for category in layer.get('categories', []):
                category_name = category.get('name', '')
                processed_categories += 1
                
                print(f"ğŸ“‹ Category [{processed_categories}]: {category_name}")
                
                questions = category.get('questions', [])
                
                # In testing mode, limit questions for this category
                if testing_mode:
                    questions_remaining = 5 - total_questions_processed
                    if questions_remaining <= 0:
                        print(f"    ğŸ§ª Testing mode: Reached 5 question limit, skipping remaining categories")
                        break
                    questions = questions[:min(len(questions), questions_remaining)]
                
                # Collect all main questions for this category
                all_main_questions = [q.get('main_question', '') for q in questions]
                total_questions_processed += len(all_main_questions)
                
                print(f"    ğŸ”„ Gom {len(all_main_questions)} questions cho comprehensive analysis...")
                
                # Create Layer 3 comprehensive analysis for entire category
                comprehensive_prompt = self.create_layer3_comprehensive_category_prompt(
                    layer_name, category_name, all_main_questions, purpose
                )
                
                print(f"    ğŸ” PhÃ¢n tÃ­ch comprehensive cho category {category_name}...")
                comprehensive_content = self.call_openai_api(comprehensive_prompt)
                
                # Store individual questions for reference (minimal processing)
                category_questions = []
                for question_data in questions:
                    question_result = {
                        'main_question': question_data.get('main_question', ''),
                        'sub_questions': question_data.get('sub_questions', []),
                        'layer3_content': None  # Not processed individually in Layer 3 mode
                    }
                    category_questions.append(question_result)
                
                # Create category result with comprehensive analysis
                category_result = {
                    'category_name': category_name,
                    'questions': category_questions,
                    'layer3_comprehensive_category': {
                        'comprehensive_content': comprehensive_content,
                        'analysis_timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
                        'questions_analyzed': all_main_questions,
                        'analysis_mode': 'Layer 3 Category Comprehensive'
                    }
                }
                
                layer_result['categories'].append(category_result)
                print(f"    âœ… HoÃ n thÃ nh comprehensive analysis cho {category_name}!")
                
                # Add delay to avoid rate limiting
                time.sleep(self.delay_seconds)
                
                # Break if we've reached the testing limit
                if testing_mode and total_questions_processed >= 5:
                    print(f"    ğŸ§ª Testing mode: Reached 5 question limit")
                    break
                
            result['research_results'].append(layer_result)
            
            # Break if we've reached the testing limit
            if testing_mode and total_questions_processed >= 5:
                break
        
        # Final statistics
        print("=" * 60)
        print("ğŸ‰ HoÃ n thÃ nh Layer 3 Category Analysis!")
        print(f"ğŸ“Š ÄÃ£ phÃ¢n tÃ­ch: {processed_categories} categories")
        if testing_mode:
            print(f"ğŸ§ª Testing mode: Processed {total_questions_processed} questions")
        
        # Add tracked references to result
        top_references = self.get_top_references(10)
        result['tracked_references'] = top_references
        
        print(f"ğŸ“š Tracked {len(self.tracked_sources)} unique sources")
        if top_references:
            print("ğŸ” Top references:")
            for source, count in top_references[:5]:
                print(f"   â€¢ {source} ({count}x)")
        
        # Add research statistics
        result['research_statistics'] = {
            'total_categories_processed': processed_categories,
            'total_questions_processed': total_questions_processed,
            'total_sources_tracked': len(self.tracked_sources),
            'total_api_calls': processed_categories,  # One call per category
            'processing_time_estimate': f"{processed_categories * self.delay_seconds / 60:.1f} minutes",
            'analysis_mode': 'Layer 3 Category Comprehensive'
        }
        
        return result
    
    def _run_layer4_detailed_analysis(self, structured_data: dict, purpose: str, result: dict, testing_mode: bool) -> dict:
        """Layer 4 Analysis Mode: Detailed analysis per main question (current behavior)"""
        
        print("ğŸ¯ Cháº¿ Ä‘á»™ Layer 4: PhÃ¢n tÃ­ch chi tiáº¿t theo main question")
        processed_questions = 0
        total_questions = 0
        total_questions_available = 0
        
        # Count total questions available
        for layer in structured_data.get('layers', []):
            for category in layer.get('categories', []):
                questions = category.get('questions', [])
                total_questions_available += len(questions)
        
        if testing_mode:
            total_questions = min(5, total_questions_available)  # Limit to exactly 5 questions
            print(f"ğŸ§ª Testing mode: Limiting to {total_questions} questions out of {total_questions_available} available")
        else:
            total_questions = total_questions_available
        
        questions_remaining = total_questions if testing_mode else float('inf')
        
        for layer in structured_data.get('layers', []):
            layer_name = layer.get('name', '')
            layer_result = {
                'layer_name': layer_name,
                'categories': []
            }
            
            print(f"ğŸ”¥ Äang xá»­ lÃ½ Layer: {layer_name}")
            
            for category in layer.get('categories', []):
                category_name = category.get('name', '')
                category_result = {
                    'category_name': category_name,
                    'questions': []
                }
                
                print(f"ğŸ“‹ Category: {category_name}")
                
                questions = category.get('questions', [])
                
                # In testing mode, limit questions to remaining count
                if testing_mode:
                    questions_to_process = min(len(questions), questions_remaining)
                    questions = questions[:questions_to_process]
                    questions_remaining -= questions_to_process
                
                for question_data in questions:
                    if testing_mode and processed_questions >= total_questions:
                        break  # Stop if we've reached the limit
                        
                    processed_questions += 1
                    progress_percent = (processed_questions / total_questions) * 100
                    
                    main_question = question_data.get('main_question', '')
                    sub_questions = question_data.get('sub_questions', [])
                    
                    print(f"  â“ [{processed_questions}/{total_questions}] ({progress_percent:.1f}%) Processing: {main_question[:50]}...")
                    
                    # Create Layer 3 analysis
                    print("    ğŸ”„ Táº¡o Layer 3 prompt...")
                    layer3_prompt = self.create_layer3_prompt_request(
                        layer_name, category_name, main_question, purpose
                    )
                    
                    print("    ğŸ” NghiÃªn cá»©u Layer 3...")
                    layer3_content = self.call_openai_api(layer3_prompt)
                    
                    # Create question result
                    question_result = {
                        'main_question': main_question,
                        'sub_questions': sub_questions,
                        'layer3_content': layer3_content
                    }
                    
                    # Auto Layer 4 comprehensive if has sub-questions
                    if sub_questions and len(sub_questions) > 0:
                        print(f"ğŸ”„ Táº¡o bÃ¡o cÃ¡o Layer 4 tá»•ng há»£p vá»›i {len(sub_questions)} sub-questions...")
                        
                        # Create temporary structure with current question data for Layer 4 enhancement
                        temp_structure = {
                            'research_results': [{
                                'layer_name': layer_name,
                                'categories': [{
                                    'category_name': category_name,
                                    'questions': [question_result]  # Include current question with layer3_content
                                }]
                            }],
                            'purpose': purpose
                        }
                        
                        comprehensive_content = self.enhance_to_layer4_comprehensive(
                            temp_structure, 
                            layer_name, 
                            category_name, 
                            main_question
                        )
                        
                        question_result['layer4_comprehensive_report'] = {
                            "comprehensive_content": comprehensive_content,
                            "enhancement_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                            "sub_questions_integrated": sub_questions
                        }
                    
                    category_result['questions'].append(question_result)
                    print("    âœ… HoÃ n thÃ nh Layer 3!")
                    
                    # Add delay to avoid rate limiting
                    time.sleep(self.delay_seconds)
                
                if category_result['questions']:  # Only add category if it has questions
                    layer_result['categories'].append(category_result)
                
                # Break early if we've reached the testing limit
                if testing_mode and processed_questions >= total_questions:
                    break
                    
            if layer_result['categories']:  # Only add layer if it has categories
                result['research_results'].append(layer_result)
                
            # Break early if we've reached the testing limit
            if testing_mode and processed_questions >= total_questions:
                break
        
        print("=" * 60)
        print("ğŸ‰ HoÃ n thÃ nh nghiÃªn cá»©u thá»‹ trÆ°á»ng Layer 4!")
        print(f"ğŸ“Š ÄÃ£ xá»­ lÃ½: {processed_questions} main questions")
        
        # Add tracked references to result
        top_references = self.get_top_references(10)
        result['tracked_references'] = top_references
        
        print(f"ğŸ“š Tracked {len(self.tracked_sources)} unique sources")
        if top_references:
            print("ğŸ” Top references:")
            for source, count in top_references[:5]:
                print(f"   â€¢ {source} ({count}x)")
        
        # Add research statistics
        result['research_statistics'] = {
            'total_questions_processed': processed_questions,
            'total_sources_tracked': len(self.tracked_sources),
            'total_api_calls': processed_questions * 2,  # Estimate including Layer 4
            'processing_time_estimate': f"{processed_questions * self.delay_seconds / 60:.1f} minutes",
            'analysis_mode': 'Layer 4 Detailed per Question'
        }
        
        return result

    def get_vietnamese_market_name(self, market: str) -> str:
        """Translate market name to Vietnamese for consistent Vietnamese reports"""
        market_translations = {
            "ğŸ‡ºğŸ‡¸ United States": "ğŸ‡ºğŸ‡¸ Hoa Ká»³",
            "ğŸ‡¨ğŸ‡³ China": "ğŸ‡¨ğŸ‡³ Trung Quá»‘c", 
            "ğŸ‡¯ğŸ‡µ Japan": "ğŸ‡¯ğŸ‡µ Nháº­t Báº£n",
            "ğŸ‡°ğŸ‡· South Korea": "ğŸ‡°ğŸ‡· HÃ n Quá»‘c",
            "ğŸ‡¹ğŸ‡­ Thailand": "ğŸ‡¹ğŸ‡­ ThÃ¡i Lan",
            "ğŸ‡¸ğŸ‡¬ Singapore": "ğŸ‡¸ğŸ‡¬ Singapore",
            "ğŸ‡²ğŸ‡¾ Malaysia": "ğŸ‡²ğŸ‡¾ Malaysia",
            "ğŸ‡®ğŸ‡© Indonesia": "ğŸ‡®ğŸ‡© Indonesia",
            "ğŸ‡µğŸ‡­ Philippines": "ğŸ‡µğŸ‡­ Philippines",
            "ğŸ‡¬ğŸ‡§ United Kingdom": "ğŸ‡¬ğŸ‡§ VÆ°Æ¡ng quá»‘c Anh",
            "ğŸ‡©ğŸ‡ª Germany": "ğŸ‡©ğŸ‡ª Äá»©c",
            "ğŸ‡«ğŸ‡· France": "ğŸ‡«ğŸ‡· PhÃ¡p",
            "ğŸ‡®ğŸ‡¹ Italy": "ğŸ‡®ğŸ‡¹ Ã",
            "ğŸ‡ªğŸ‡¸ Spain": "ğŸ‡ªğŸ‡¸ TÃ¢y Ban Nha",
            "ğŸ‡¨ğŸ‡¦ Canada": "ğŸ‡¨ğŸ‡¦ Canada",
            "ğŸ‡¦ğŸ‡º Australia": "ğŸ‡¦ğŸ‡º Ãšc",
            "ğŸ‡³ğŸ‡¿ New Zealand": "ğŸ‡³ğŸ‡¿ New Zealand",
            "ğŸ‡§ğŸ‡· Brazil": "ğŸ‡§ğŸ‡· Brazil",
            "ğŸ‡²ğŸ‡½ Mexico": "ğŸ‡²ğŸ‡½ Mexico",
            "ğŸ‡®ğŸ‡³ India": "ğŸ‡®ğŸ‡³ áº¤n Äá»™",
            "ğŸ‡·ğŸ‡º Russia": "ğŸ‡·ğŸ‡º Nga",
            "ğŸ‡¿ğŸ‡¦ South Africa": "ğŸ‡¿ğŸ‡¦ Nam Phi",
            "ğŸ‡ªğŸ‡¬ Egypt": "ğŸ‡ªğŸ‡¬ Ai Cáº­p",
            "ğŸ‡¦ğŸ‡ª UAE": "ğŸ‡¦ğŸ‡ª UAE",
            "ğŸ‡¸ğŸ‡¦ Saudi Arabia": "ğŸ‡¸ğŸ‡¦ áº¢ Ráº­p Saudi",
            "ğŸ‡¹ğŸ‡· Turkey": "ğŸ‡¹ğŸ‡· Thá»• NhÄ© Ká»³",
            "ğŸ‡³ğŸ‡± Netherlands": "ğŸ‡³ğŸ‡± HÃ  Lan",
            "ğŸ‡¸ğŸ‡ª Sweden": "ğŸ‡¸ğŸ‡ª Thá»¥y Äiá»ƒn",
            "ğŸ‡³ğŸ‡´ Norway": "ğŸ‡³ğŸ‡´ Na Uy",
            "ğŸ‡©ğŸ‡° Denmark": "ğŸ‡©ğŸ‡° Äan Máº¡ch",
            "ğŸ‡«ğŸ‡® Finland": "ğŸ‡«ğŸ‡® Pháº§n Lan",
            "ğŸ‡¨ğŸ‡­ Switzerland": "ğŸ‡¨ğŸ‡­ Thá»¥y SÄ©",
            "ğŸ‡¦ğŸ‡¹ Austria": "ğŸ‡¦ğŸ‡¹ Ão",
            "ğŸ‡§ğŸ‡ª Belgium": "ğŸ‡§ğŸ‡ª Bá»‰",
            "ğŸ‡µğŸ‡± Poland": "ğŸ‡µğŸ‡± Ba Lan",
            "ğŸ‡¨ğŸ‡¿ Czech Republic": "ğŸ‡¨ğŸ‡¿ Cá»™ng hÃ²a SÃ©c",
            "ğŸ‡­ğŸ‡º Hungary": "ğŸ‡­ğŸ‡º Hungary",
            "ğŸ‡¬ğŸ‡· Greece": "ğŸ‡¬ğŸ‡· Hy Láº¡p",
            "ğŸ‡µğŸ‡¹ Portugal": "ğŸ‡µğŸ‡¹ Bá»“ ÄÃ o Nha",
            "ğŸ‡®ğŸ‡ª Ireland": "ğŸ‡®ğŸ‡ª Ireland",
            "ğŸ‡®ğŸ‡± Israel": "ğŸ‡®ğŸ‡± Israel",
            "ğŸ‡­ğŸ‡° Hong Kong": "ğŸ‡­ğŸ‡° Há»“ng KÃ´ng",
            "ğŸ‡¹ğŸ‡¼ Taiwan": "ğŸ‡¹ğŸ‡¼ ÄÃ i Loan",
            "ğŸ‡¦ğŸ‡· Argentina": "ğŸ‡¦ğŸ‡· Argentina",
            "ğŸ‡¨ğŸ‡± Chile": "ğŸ‡¨ğŸ‡± Chile",
            "ğŸ‡¨ğŸ‡´ Colombia": "ğŸ‡¨ğŸ‡´ Colombia",
            "ğŸ‡µğŸ‡ª Peru": "ğŸ‡µğŸ‡ª Peru",
            "ğŸ‡»ğŸ‡ª Venezuela": "ğŸ‡»ğŸ‡ª Venezuela",
            "ğŸ‡ªğŸ‡¨ Ecuador": "ğŸ‡ªğŸ‡¨ Ecuador",
            "ğŸ‡ºğŸ‡¾ Uruguay": "ğŸ‡ºğŸ‡¾ Uruguay",
            "ğŸ‡§ğŸ‡´ Bolivia": "ğŸ‡§ğŸ‡´ Bolivia",
            "ğŸ‡µğŸ‡¾ Paraguay": "ğŸ‡µğŸ‡¾ Paraguay",
            "ğŸ‡³ğŸ‡¬ Nigeria": "ğŸ‡³ğŸ‡¬ Nigeria",
            "ğŸ‡°ğŸ‡ª Kenya": "ğŸ‡°ğŸ‡ª Kenya",
            "ğŸ‡¬ğŸ‡­ Ghana": "ğŸ‡¬ğŸ‡­ Ghana",
            "ğŸ‡ªğŸ‡¹ Ethiopia": "ğŸ‡ªğŸ‡¹ Ethiopia",
            "ğŸ‡ºğŸ‡¬ Uganda": "ğŸ‡ºğŸ‡¬ Uganda",
            "ğŸ‡¹ğŸ‡¿ Tanzania": "ğŸ‡¹ğŸ‡¿ Tanzania",
            "ğŸ‡¿ğŸ‡¼ Zimbabwe": "ğŸ‡¿ğŸ‡¼ Zimbabwe",
            "ğŸŒ Southeast Asia": "ğŸŒ ÄÃ´ng Nam Ã",
            "ğŸŒ Asia-Pacific": "ğŸŒ ChÃ¢u Ã - ThÃ¡i BÃ¬nh DÆ°Æ¡ng",
            "ğŸŒ Global Market": "ğŸŒ Thá»‹ trÆ°á»ng ToÃ n cáº§u"
        }
        
        return market_translations.get(market, market) 