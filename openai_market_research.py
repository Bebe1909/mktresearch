#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script gá»­i request tá»›i OpenAI GPT API Ä‘á»ƒ nghiÃªn cá»©u thá»‹ trÆ°á»ng
TÃ¡c giáº£: AI Assistant
NgÃ y: 2024
"""

import json
import requests
import time
from typing import Dict, List, Any
import openai

class OpenAIMarketResearch:
    def __init__(self, api_key: str, industry: str = "Technology", market: str = "Viá»‡t Nam", model: str = "gpt-3.5-turbo"):
        """
        Khá»Ÿi táº¡o class nghiÃªn cá»©u thá»‹ trÆ°á»ng vá»›i OpenAI GPT
        
        Args:
            api_key (str): API key cá»§a OpenAI
            industry (str): NgÃ nh cÃ´ng nghiá»‡p nghiÃªn cá»©u
            market (str): Thá»‹ trÆ°á»ng nghiÃªn cá»©u
            model (str): Model GPT sá»­ dá»¥ng
        """
        self.client = openai.OpenAI(api_key=api_key)
        self.industry = industry
        self.market = market
        self.model = model
        self.base_url = "https://api.openai.com/v1/chat/completions"
        self.delay_seconds = 3  # Increased delay from 1 to 3 seconds
        
        # Reference tracking system
        self.reference_tracker = {}
        self.tracked_sources = set()
        
        print(f"ğŸ¤– Initialized OpenAI Market Research for {industry} in {market}")
        print(f"ğŸ“Š API Provider: OpenAI")
        print(f"ğŸ”§ Model: {model}")
        
    def call_openai_api(self, prompt: str, max_retries: int = 3) -> str:
        """Gá»­i request tá»›i OpenAI API vá»›i retry logic vÃ  track references"""
        
        for attempt in range(max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    max_tokens=2000,
                    temperature=0.7
                )
                
                if response.choices and response.choices[0].message:
                    content = response.choices[0].message.content
                    
                    # Track references from the response
                    self.track_references_from_response(content)
                    
                    return content
                else:
                    return "KhÃ´ng cÃ³ ná»™i dung trong pháº£n há»“i API"
                    
            except Exception as e:
                if "429" in str(e) or "rate_limit" in str(e).lower():  # Rate limit error
                    wait_time = (2 ** attempt) * 5  # Exponential backoff: 5, 10, 20 seconds
                    print(f"âš ï¸ Rate limit hit - Waiting {wait_time}s before retry {attempt + 1}/{max_retries}")
                    time.sleep(wait_time)
                    if attempt == max_retries - 1:
                        print(f"âŒ Max retries reached. Error: {e}")
                        return f"Rate limit error after {max_retries} retries: {e}"
                else:
                    print(f"âŒ API Error: {e}")
                    return f"API Error: {e}"
        
        return "Failed after all retries"
    
    def track_references_from_response(self, content: str):
        """Extract and track references from AI response"""
        import re
        
        # Patterns to detect references and sources in AI responses
        reference_patterns = [
            # Organizations and institutions
            r'\b(?:Tá»•ng cá»¥c Thá»‘ng kÃª|General Statistics Office|GSO)\b',
            r'\b(?:NgÃ¢n hÃ ng Tháº¿ giá»›i|World Bank)\b',
            r'\b(?:IMF|International Monetary Fund)\b',
            r'\b(?:ADB|Asian Development Bank)\b',
            r'\b(?:McKinsey|Deloitte|PwC|KPMG|BCG)\b',
            r'\b(?:Nielsen|Euromonitor|Statista)\b',
            r'\b(?:VCCI|Vietnam Chamber of Commerce)\b',
            r'\b(?:Bá»™ (?:Káº¿ hoáº¡ch|TÃ i chÃ­nh|CÃ´ng ThÆ°Æ¡ng|Y táº¿|GiÃ¡o dá»¥c))\b',
            
            # Vietnam specific
            r'\b(?:VAMA|Vietnam Automobile)\b',
            r'\b(?:VINASA|Vietnam Software)\b',
            r'\b(?:VFA|Vietnam Food Association)\b',
            r'\b(?:FPT|Viettel|VNPT)\b',
            r'\b(?:NgÃ¢n hÃ ng NhÃ  nÆ°á»›c|State Bank of Vietnam)\b',
            
            # Global sources
            r'\b(?:Bloomberg|Reuters|Financial Times)\b',
            r'\b(?:Forbes|Harvard Business Review|MIT)\b',
            r'\b(?:Gartner|IDC|Forrester)\b',
            
            # Government and regulatory
            r'\b(?:Ministry of|Bá»™)\s+[A-Za-zÃ€-á»¹\s]+\b',
            r'\b(?:Government of|ChÃ­nh phá»§)\s+[A-Za-zÃ€-á»¹\s]+\b',
        ]
        
        # Extract references
        for pattern in reference_patterns:
            matches = re.finditer(pattern, content, re.IGNORECASE)
            for match in matches:
                source = match.group().strip()
                if source and len(source) > 3:  # Avoid very short matches
                    # Normalize source name
                    normalized_source = self.normalize_source_name(source)
                    
                    # Track frequency
                    if normalized_source in self.reference_tracker:
                        self.reference_tracker[normalized_source] += 1
                    else:
                        self.reference_tracker[normalized_source] = 1
                    
                    self.tracked_sources.add(normalized_source)
    
    def normalize_source_name(self, source: str) -> str:
        """Normalize source names for consistent tracking"""
        source = source.strip()
        
        # Mapping for common variations
        mappings = {
            'Tá»•ng cá»¥c Thá»‘ng kÃª': 'General Statistics Office (GSO)',
            'General Statistics Office': 'General Statistics Office (GSO)',
            'GSO': 'General Statistics Office (GSO)',
            'NgÃ¢n hÃ ng Tháº¿ giá»›i': 'World Bank',
            'World Bank': 'World Bank',
            'IMF': 'International Monetary Fund (IMF)',
            'International Monetary Fund': 'International Monetary Fund (IMF)',
            'McKinsey': 'McKinsey & Company',
            'Deloitte': 'Deloitte Consulting',
            'PwC': 'PricewaterhouseCoopers (PwC)',
            'KPMG': 'KPMG International',
            'Nielsen': 'Nielsen Holdings',
            'Euromonitor': 'Euromonitor International',
            'Statista': 'Statista GmbH',
            'VCCI': 'Vietnam Chamber of Commerce and Industry (VCCI)',
            'Vietnam Chamber of Commerce': 'Vietnam Chamber of Commerce and Industry (VCCI)',
        }
        
        return mappings.get(source, source)
    
    def get_top_references(self, limit: int = 10) -> list:
        """Get top references sorted by frequency"""
        sorted_refs = sorted(
            self.reference_tracker.items(), 
            key=lambda x: x[1], 
            reverse=True
        )
        return sorted_refs[:limit]

    def create_layer3_prompt_request(self, layer1: str, layer2: str, main_question: str, purpose: str) -> str:
        """Táº¡o request Ä‘á»ƒ láº¥y prompt Layer 3 (main question level) - DIRECT ANSWER FOCUSED"""
        template = f'''Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch thá»‹ trÆ°á»ng cho ngÃ nh "{self.industry}" táº¡i thá»‹ trÆ°á»ng "{self.market}".

Má»¤C ÄÃCH NGHIÃŠN Cá»¨U: {purpose}

NGá»® Cáº¢NH PHÃ‚N TÃCH:
- Chá»§ Ä‘á» chÃ­nh: {layer1}
- LÄ©nh vá»±c: {layer2}

CÃ‚U Há»I Cáº¦N TRáº¢ Lá»œI: "{main_question}"

ğŸ¯ **YÃŠU Cáº¦U Báº®T BUá»˜C:**
1. **TRáº¢ Lá»œI TRá»°C TIáº¾P** cÃ¢u há»i ngay tá»« cÃ¢u Ä‘áº§u tiÃªn
2. **Báº®T Äáº¦U** báº±ng: "Äá»ƒ tráº£ lá»i cÃ¢u há»i vá» [tÃ³m táº¯t ngáº¯n cÃ¢u há»i]..."
3. **FOCUS 100%** vÃ o ná»™i dung mÃ  cÃ¢u há»i Ä‘ang há»i - khÃ´ng drift sang chá»§ Ä‘á» khÃ¡c
4. **Sá»¬ Dá»¤NG** sá»‘ liá»‡u vÃ  vÃ­ dá»¥ cá»¥ thá»ƒ tá»« thá»‹ trÆ°á»ng {self.market}
5. **Káº¾T THÃšC** báº±ng conclusion tráº£ lá»i rÃµ rÃ ng cÃ¢u há»i

**Cáº¤U TRÃšC:**
- Äoáº¡n 1: Tráº£ lá»i trá»±c tiáº¿p + evidence chÃ­nh (3-4 cÃ¢u)
- Äoáº¡n 2: PhÃ¢n tÃ­ch deeper vá»›i data/examples (3-4 cÃ¢u)  
- Äoáº¡n 3: Impact/implications vÃ  conclusion (2-3 cÃ¢u)

**TRÃNH:**
- NÃ³i chung chung hoáº·c láº¡c Ä‘á»
- Äáº·t cÃ¢u há»i thÃªm
- PhÃ¢n tÃ­ch nhá»¯ng gÃ¬ khÃ´ng Ä‘Æ°á»£c há»i

**CHá»ˆ Táº¬P TRUNG:** Tráº£ lá»i chÃ­nh xÃ¡c vÃ  Ä‘áº§y Ä‘á»§ cÃ¢u há»i "{main_question}"'''
        
        return template

    def create_layer4_enhancement_prompt(self, layer1: str, layer2: str, main_question: str, sub_question: str, layer3_content: str, purpose: str) -> str:
        """Táº¡o prompt Ä‘á»ƒ enhance specific section tá»« Layer 3 lÃªn Layer 4"""
        template = f'''As a master prompt engineer, I need to enhance a specific section of an existing market research report from Layer 3 to Layer 4 standard for: "{self.industry}" in market: "{self.market}". 

The research purpose is: "{purpose}"
Structure: layer 1: {layer1} | layer 2: {layer2} | layer 3: {main_question}

EXISTING LAYER 3 CONTENT TO ENHANCE:
{layer3_content}

SPECIFIC ENHANCEMENT REQUEST (Layer 4):
{sub_question}

Create a prompt for GPT to provide deep, detailed analysis specifically for the enhancement request above, while building upon the existing Layer 3 content. The result should be much more detailed, with specific data, examples, and actionable insights. Vietnamese answer only.'''
        
        return template

    def create_layer4_comprehensive_report_prompt(self, layer1: str, layer2: str, main_question: str, sub_questions: list, layer3_content: str, purpose: str) -> str:
        """Táº¡o prompt Ä‘á»ƒ táº¡o bÃ¡o cÃ¡o Layer 4 tá»•ng há»£p - DIRECT CONTENT, NO INTRO"""
        
        sub_questions_text = "\n".join([f"- {sq}" for sq in sub_questions])
        
        template = f'''Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch thá»‹ trÆ°á»ng cho ngÃ nh "{self.industry}" táº¡i thá»‹ trÆ°á»ng "{self.market}".

NGá»® Cáº¢NH: {layer1} > {layer2}
CÃ‚U Há»I CHÃNH Cáº¦N TRáº¢ Lá»œI: "{main_question}"

PHÃ‚N TÃCH Sáº´N CÃ“ (Layer 3):
{layer3_content}

CÃC KHÃA Cáº NH CHI TIáº¾T Cáº¦N PHÃ‚N TÃCH:
{sub_questions_text}

ğŸ¯ **NHIá»†M Vá»¤:** Viáº¿t phÃ¢n tÃ­ch chuyÃªn sÃ¢u tráº£ lá»i cÃ¢u há»i chÃ­nh "{main_question}" báº±ng cÃ¡ch tÃ­ch há»£p táº¥t cáº£ khÃ­a cáº¡nh chi tiáº¿t.

**Báº®T Äáº¦U NGAY Vá»šI Ná»˜I DUNG PHÃ‚N TÃCH** - KHÃ”NG cÃ³ cÃ¢u giá»›i thiá»‡u, khÃ´ng cÃ³ "Äá»ƒ tráº£ lá»i cÃ¢u há»i...", Ä‘i tháº³ng vÃ o tÃ¬nh hÃ¬nh hiá»‡n táº¡i.

**CÃCH VIáº¾T - FLOW Tá»° NHIÃŠN:**

Viáº¿t má»™t phÃ¢n tÃ­ch dáº¡ng vÄƒn xuÃ´i, liá»n máº¡ch theo logic:
1. **TÃ¬nh hÃ¬nh hiá»‡n táº¡i** (120-150 tá»«): Báº¯t Ä‘áº§u ngay vá»›i phÃ¢n tÃ­ch tÃ¬nh tráº¡ng hiá»‡n táº¡i, data cá»¥ thá»ƒ
2. **Äá»™ng lá»±c vÃ  tÃ¡c Ä‘á»™ng** (120-150 tá»«): Drivers chÃ­nh, impacts lÃªn players vÃ  consumers
3. **CÆ¡ há»™i vÃ  xu hÆ°á»›ng** (120-150 tá»«): Opportunities, growth areas, success cases
4. **ThÃ¡ch thá»©c vÃ  rá»§i ro** (80-120 tá»«): Barriers, risks cáº§n monitor
5. **Khuyáº¿n nghá»‹ chiáº¿n lÆ°á»£c** (100-120 tá»«): Actionable steps cá»¥ thá»ƒ

**YÃŠU Cáº¦U CRITICAL:**
- Báº®T Äáº¦U NGAY báº±ng cÃ¢u vá» tÃ¬nh hÃ¬nh thá»±c táº¿ (VD: "Hiá»‡n táº¡i thá»‹ trÆ°á»ng...", "Trong bá»‘i cáº£nh...", "TÃ¬nh tráº¡ng hiá»‡n táº¡i...")
- KHÃ”NG sá»­ dá»¥ng section headers hay bullet points
- KHÃ”NG cÃ³ cÃ¢u giá»›i thiá»‡u hay má»Ÿ Ä‘áº§u
- VIáº¾T liá»n máº¡ch nhÆ° má»™t bÃ i phÃ¢n tÃ­ch chuyÃªn nghiá»‡p
- Use real {self.market} market data vÃ  case studies
- BE SPECIFIC - trÃ¡nh generalities
- Total: 550-700 tá»«

**PHONG CÃCH:**
- VÄƒn xuÃ´i professional, máº¡ch láº¡c
- Transition tá»± nhiÃªn giá»¯a cÃ¡c Ã½
- Báº¯t Ä‘áº§u ngay vá»›i facts vÃ  analysis
- Flow nhÆ° má»™t essay analysis, khÃ´ng intro

**VÃ Dá»¤ Báº®T Äáº¦U Tá»T:**
"Hiá»‡n táº¡i ngÃ nh [X] Ä‘ang tráº£i qua..."
"Trong bá»‘i cáº£nh thá»‹ trÆ°á»ng [Y]..."
"TÃ¬nh tráº¡ng hiá»‡n táº¡i cho tháº¥y..."
"Thá»‹ trÆ°á»ng [Z] Ä‘ang chá»©ng kiáº¿n..."

**Káº¾T THÃšC** vá»›i conclusion tráº£ lá»i hoÃ n chá»‰nh cÃ¢u há»i chÃ­nh.'''
        
        return template

    def process_layer3_research(self, json_file: str = "market_research_structured.json", limit: int = None) -> Dict[str, Any]:
        """
        Xá»­ lÃ½ nghiÃªn cá»©u thá»‹ trÆ°á»ng á»Ÿ Layer 3 standard (main questions only)
        
        Args:
            json_file (str): ÄÆ°á»ng dáº«n file JSON chá»©a dá»¯ liá»‡u
            limit (int): Giá»›i háº¡n sá»‘ questions Ä‘á»ƒ test (None = unlimited)
            
        Returns:
            Dict: Káº¿t quáº£ nghiÃªn cá»©u thá»‹ trÆ°á»ng Layer 3
        """
        
        # Äá»c file JSON
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        purpose = data.get('purpose', '')
        layers = data.get('layers', [])
        
        results = {
            "industry": self.industry,
            "market": self.market,
            "purpose": purpose,
            "research_standard": "Layer 3",
            "api_provider": "openai",
            "model_used": self.model,
            "research_results": []
        }
        
        total_questions = 0
        processed_questions = 0
        
        # Äáº¿m tá»•ng sá»‘ main questions (Layer 3)
        for layer in layers:
            for category in layer.get('categories', []):
                total_questions += len(category.get('questions', []))
        
        # Apply limit if specified
        if limit:
            total_questions = min(total_questions, limit)
            print(f"ğŸš§ Testing mode: Giá»›i háº¡n {limit} questions")
        
        print(f"ğŸ¯ Báº¯t Ä‘áº§u nghiÃªn cá»©u thá»‹ trÆ°á»ng Layer 3: {self.industry}")
        print(f"ğŸ“Š Thá»‹ trÆ°á»ng: {self.market}")
        print(f"ğŸ¤– API: OpenAI {self.model}")
        print(f"â“ Tá»•ng sá»‘ main questions (Layer 3): {total_questions}")
        print("="*60)
        
        for layer in layers:
            layer_name = layer.get('name', '')
            layer_result = {
                "layer_name": layer_name,
                "categories": []
            }
            
            print(f"\nğŸ”¥ Äang xá»­ lÃ½ Layer: {layer_name}")
            
            for category in layer.get('categories', []):
                category_name = category.get('name', '')
                category_result = {
                    "category_name": category_name,
                    "questions": []
                }
                
                print(f"ğŸ“‹ Category: {category_name}")
                
                for question in category.get('questions', []):
                    # Check limit
                    if limit and processed_questions >= limit:
                        print(f"ğŸš§ ÄÃ£ Ä‘áº¡t giá»›i háº¡n {limit} questions, dá»«ng láº¡i.")
                        break
                        
                    main_question = question.get('main_question', '')
                    processed_questions += 1
                    progress = (processed_questions / total_questions) * 100
                    
                    print(f"  â“ [{processed_questions}/{total_questions}] ({progress:.1f}%) Processing: {main_question[:50]}...")
                    
                    # BÆ°á»›c 1: Táº¡o Layer 3 prompt request
                    prompt_request = self.create_layer3_prompt_request(
                        layer_name, category_name, main_question, purpose
                    )
                    
                    # BÆ°á»›c 2: Gá»­i request Ä‘á»ƒ láº¥y prompt
                    print(f"    ğŸ”„ Táº¡o Layer 3 prompt...")
                    generated_prompt = self.call_openai_api(prompt_request)
                    
                    # BÆ°á»›c 3: Sá»­ dá»¥ng prompt Ä‘á»ƒ láº¥y káº¿t quáº£ Layer 3
                    print(f"    ğŸ” NghiÃªn cá»©u Layer 3...")
                    research_result = self.call_openai_api(generated_prompt)
                    
                    # LÆ°u káº¿t quáº£ vá»›i cáº¥u trÃºc má»›i cho Layer 3
                    question_result = {
                        "main_question": main_question,
                        "research_standard": "Layer 3",
                        "generated_prompt": generated_prompt,
                        "layer3_content": research_result,
                        "sub_questions": question.get('sub_questions', []),  # LÆ°u Ä‘á»ƒ cÃ³ thá»ƒ enhance sau
                        "layer4_enhancements": {}  # Dict Ä‘á»ƒ lÆ°u cÃ¡c enhancement
                    }
                    
                    category_result["questions"].append(question_result)
                    
                    # Delay Ä‘á»ƒ trÃ¡nh rate limit
                    time.sleep(self.delay_seconds)
                    
                    print(f"    âœ… HoÃ n thÃ nh Layer 3!")
                
                if category_result["questions"]:  # Only add if has questions
                    layer_result["categories"].append(category_result)
                    
                # Check limit
                if limit and processed_questions >= limit:
                    break
            
            if layer_result["categories"]:  # Only add if has categories
                results["research_results"].append(layer_result)
                
            # Check limit
            if limit and processed_questions >= limit:
                break
        
        print("\n" + "="*60)
        print(f"ğŸ‰ HoÃ n thÃ nh nghiÃªn cá»©u thá»‹ trÆ°á»ng Layer 3!")
        print(f"ğŸ“Š ÄÃ£ xá»­ lÃ½: {processed_questions} main questions")
        
        return results

    def enhance_to_layer4(self, layer3_results: Dict[str, Any], layer_name: str, category_name: str, main_question: str, sub_question: str) -> str:
        """
        Enhance má»™t section cá»¥ thá»ƒ tá»« Layer 3 lÃªn Layer 4
        """
        
        # TÃ¬m layer3_content tÆ°Æ¡ng á»©ng
        layer3_content = ""
        purpose = layer3_results.get('purpose', '')
        
        for layer in layer3_results.get('research_results', []):
            if layer.get('layer_name') == layer_name:
                for category in layer.get('categories', []):
                    if category.get('category_name') == category_name:
                        for question in category.get('questions', []):
                            if question.get('main_question') == main_question:
                                layer3_content = question.get('layer3_content', '')
                                break
        
        if not layer3_content:
            return "KhÃ´ng tÃ¬m tháº¥y ná»™i dung Layer 3 Ä‘á»ƒ enhance"
        
        print(f"ğŸ”„ Enhancing to Layer 4: {sub_question[:50]}...")
        
        # BÆ°á»›c 1: Táº¡o enhancement prompt
        enhancement_prompt_request = self.create_layer4_enhancement_prompt(
            layer_name, category_name, main_question, sub_question, layer3_content, purpose
        )
        
        # BÆ°á»›c 2: Láº¥y enhancement prompt
        print(f"    ğŸ”„ Táº¡o Layer 4 enhancement prompt...")
        generated_prompt = self.call_openai_api(enhancement_prompt_request)
        
        # BÆ°á»›c 3: Cháº¡y enhancement
        print(f"    ğŸ” Thá»±c hiá»‡n Layer 4 enhancement...")
        enhancement_result = self.call_openai_api(generated_prompt)
        
        print(f"    âœ… HoÃ n thÃ nh Layer 4 enhancement!")
        
        return enhancement_result

    def enhance_to_layer4_comprehensive(self, layer3_results: Dict[str, Any], layer_name: str, category_name: str, main_question: str) -> str:
        """
        Táº¡o bÃ¡o cÃ¡o Layer 4 tá»•ng há»£p cho toÃ n bá»™ main question (táº¥t cáº£ sub-questions)
        """
        
        # TÃ¬m layer3_content vÃ  sub_questions tÆ°Æ¡ng á»©ng
        layer3_content = ""
        sub_questions = []
        purpose = layer3_results.get('purpose', '')
        
        for layer in layer3_results.get('research_results', []):
            if layer.get('layer_name') == layer_name:
                for category in layer.get('categories', []):
                    if category.get('category_name') == category_name:
                        for question in category.get('questions', []):
                            if question.get('main_question') == main_question:
                                layer3_content = question.get('layer3_content', '')
                                sub_questions = question.get('sub_questions', [])
                                break
        
        if not layer3_content:
            return "KhÃ´ng tÃ¬m tháº¥y ná»™i dung Layer 3 Ä‘á»ƒ enhance"
        
        if not sub_questions:
            return "KhÃ´ng tÃ¬m tháº¥y sub-questions Ä‘á»ƒ táº¡o bÃ¡o cÃ¡o tá»•ng há»£p"
        
        print(f"ğŸ”„ Táº¡o bÃ¡o cÃ¡o Layer 4 tá»•ng há»£p vá»›i {len(sub_questions)} sub-questions...")
        
        # Táº¡o comprehensive report prompt
        comprehensive_prompt = self.create_layer4_comprehensive_report_prompt(
            layer_name, category_name, main_question, sub_questions, layer3_content, purpose
        )
        
        # Gá»i API Ä‘á»ƒ táº¡o comprehensive report
        print(f"    ğŸ” Thá»±c hiá»‡n Layer 4 comprehensive analysis...")
        comprehensive_report = self.call_openai_api(comprehensive_prompt)
        
        print(f"    âœ… HoÃ n thÃ nh Layer 4 comprehensive report!")
        
        return comprehensive_report

    def add_layer4_enhancement(self, results_file: str, layer_name: str, category_name: str, main_question: str, sub_question: str, output_file: str = None) -> str:
        """
        ThÃªm Layer 4 enhancement vÃ o káº¿t quáº£ hiá»‡n cÃ³ vÃ  lÆ°u file
        """
        
        # Äá»c káº¿t quáº£ hiá»‡n cÃ³
        with open(results_file, 'r', encoding='utf-8') as f:
            results = json.load(f)
        
        # Thá»±c hiá»‡n enhancement
        enhancement_content = self.enhance_to_layer4(results, layer_name, category_name, main_question, sub_question)
        
        # Cáº­p nháº­t káº¿t quáº£
        for layer in results.get('research_results', []):
            if layer.get('layer_name') == layer_name:
                for category in layer.get('categories', []):
                    if category.get('category_name') == category_name:
                        for question in category.get('questions', []):
                            if question.get('main_question') == main_question:
                                # ThÃªm enhancement vÃ o dict
                                question['layer4_enhancements'][sub_question] = {
                                    "enhanced_content": enhancement_content,
                                    "enhancement_timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                                }
                                break
        
        # LÆ°u file
        if output_file is None:
            output_file = results_file  # Ghi Ä‘Ã¨ file gá»‘c
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ÄÃ£ cáº­p nháº­t Layer 4 enhancement vÃ o: {output_file}")
        return output_file

    def add_layer4_comprehensive_enhancement(self, results_file: str, layer_name: str, category_name: str, main_question: str, output_file: str = None) -> str:
        """
        ThÃªm Layer 4 comprehensive enhancement vÃ o káº¿t quáº£ hiá»‡n cÃ³ vÃ  lÆ°u file
        """
        
        # Äá»c káº¿t quáº£ hiá»‡n cÃ³
        with open(results_file, 'r', encoding='utf-8') as f:
            results = json.load(f)
        
        # Thá»±c hiá»‡n comprehensive enhancement
        comprehensive_content = self.enhance_to_layer4_comprehensive(results, layer_name, category_name, main_question)
        
        # Cáº­p nháº­t káº¿t quáº£ vá»›i comprehensive report
        for layer in results.get('research_results', []):
            if layer.get('layer_name') == layer_name:
                for category in layer.get('categories', []):
                    if category.get('category_name') == category_name:
                        for question in category.get('questions', []):
                            if question.get('main_question') == main_question:
                                # ThÃªm comprehensive enhancement
                                question['layer4_comprehensive_report'] = {
                                    "comprehensive_content": comprehensive_content,
                                    "enhancement_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                                    "sub_questions_integrated": question.get('sub_questions', [])
                                }
                                break
        
        # LÆ°u file
        if output_file is None:
            output_file = results_file  # Ghi Ä‘Ã¨ file gá»‘c
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ÄÃ£ cáº­p nháº­t Layer 4 comprehensive report vÃ o: {output_file}")
        return output_file

    def run_layer3_research(self, structured_data: dict, topic: str, testing_mode: bool = False) -> dict:
        """Main research execution with comprehensive error handling and reference tracking"""
        
        print(f"ğŸ¯ Báº¯t Ä‘áº§u nghiÃªn cá»©u thá»‹ trÆ°á»ng Layer 3: {topic}")
        print(f"ğŸ“Š Thá»‹ trÆ°á»ng: {self.market}")
        print(f"ğŸ¤– API: OpenAI {self.model}")
        
        # Reset reference tracking for new research
        self.reference_tracker = {}
        self.tracked_sources = set()
        
        # Get purpose from structured data
        purpose = structured_data.get('purpose', 'NghiÃªn cá»©u thá»‹ trÆ°á»ng vÃ  phÃ¢n tÃ­ch cÆ¡ há»™i kinh doanh')
        
        # Create result structure
        result = {
            'research_metadata': {
                'industry': topic,
                'market': self.market,
                'model_used': self.model,
                'api_provider': 'OpenAI',
                'purpose': purpose,
                'research_timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
                'testing_mode': testing_mode
            },
            'research_results': [],
            'research_statistics': {},
            'tracked_references': []  # Will be populated at the end
        }
        
        # Count total questions for progress tracking
        total_questions = 0
        for layer in structured_data.get('layers', []):
            for category in layer.get('categories', []):
                questions = category.get('questions', [])
                if testing_mode:
                    total_questions += min(len(questions), 2)  # Limit to 2 per category in test mode
                else:
                    total_questions += len(questions)
        
        print(f"â“ Tá»•ng sá»‘ main questions (Layer 3): {total_questions}")
        print("=" * 60)
        
        processed_questions = 0
        
        for layer in structured_data.get('layers', []):
            layer_name = layer.get('name', '')
            layer_result = {
                'layer_name': layer_name,
                'categories': []
            }
            
            print(f"ğŸ”¥ Äang xá»­ lÃ½ Layer: {layer_name}")
            
            for category in layer.get('categories', []):
                category_name = category.get('name', '')
                category_result = {
                    'category_name': category_name,
                    'questions': []
                }
                
                print(f"ğŸ“‹ Category: {category_name}")
                
                questions = category.get('questions', [])
                if testing_mode:
                    questions = questions[:2]  # Limit to 2 questions per category
                
                for question_data in questions:
                    processed_questions += 1
                    progress_percent = (processed_questions / total_questions) * 100
                    
                    main_question = question_data.get('main_question', '')
                    sub_questions = question_data.get('sub_questions', [])
                    
                    print(f"  â“ [{processed_questions}/{total_questions}] ({progress_percent:.1f}%) Processing: {main_question[:50]}...")
                    
                    # Create Layer 3 analysis
                    print("    ğŸ”„ Táº¡o Layer 3 prompt...")
                    layer3_prompt = self.create_layer3_prompt_request(
                        layer_name, category_name, main_question, purpose
                    )
                    
                    print("    ğŸ” NghiÃªn cá»©u Layer 3...")
                    layer3_content = self.call_openai_api(layer3_prompt)
                    
                    # Create question result
                    question_result = {
                        'main_question': main_question,
                        'sub_questions': sub_questions,
                        'layer3_content': layer3_content
                    }
                    
                    # Auto Layer 4 comprehensive if has sub-questions
                    if sub_questions and len(sub_questions) > 0:
                        print(f"ğŸ”„ Táº¡o bÃ¡o cÃ¡o Layer 4 tá»•ng há»£p vá»›i {len(sub_questions)} sub-questions...")
                        
                        # Create temporary structure with current question data for Layer 4 enhancement
                        temp_structure = {
                            'research_results': [{
                                'layer_name': layer_name,
                                'categories': [{
                                    'category_name': category_name,
                                    'questions': [question_result]  # Include current question with layer3_content
                                }]
                            }],
                            'purpose': purpose
                        }
                        
                        comprehensive_content = self.enhance_to_layer4_comprehensive(
                            temp_structure, 
                            layer_name, 
                            category_name, 
                            main_question
                        )
                        
                        question_result['layer4_comprehensive_report'] = {
                            "comprehensive_content": comprehensive_content,
                            "enhancement_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                            "sub_questions_integrated": sub_questions
                        }
                    
                    category_result['questions'].append(question_result)
                    print("    âœ… HoÃ n thÃ nh Layer 3!")
                    
                    # Add delay to avoid rate limiting
                    time.sleep(self.delay_seconds)
                
                layer_result['categories'].append(category_result)
                
            result['research_results'].append(layer_result)
        
        print("=" * 60)
        print("ğŸ‰ HoÃ n thÃ nh nghiÃªn cá»©u thá»‹ trÆ°á»ng Layer 3!")
        print(f"ğŸ“Š ÄÃ£ xá»­ lÃ½: {processed_questions} main questions")
        
        # Add tracked references to result
        top_references = self.get_top_references(10)
        result['tracked_references'] = top_references
        
        print(f"ğŸ“š Tracked {len(self.tracked_sources)} unique sources")
        if top_references:
            print("ğŸ” Top references:")
            for source, count in top_references[:5]:
                print(f"   â€¢ {source} ({count}x)")
        
        # Add research statistics
        result['research_statistics'] = {
            'total_questions_processed': processed_questions,
            'total_sources_tracked': len(self.tracked_sources),
            'total_api_calls': processed_questions * 2,  # Estimate including Layer 4
            'processing_time_estimate': f"{processed_questions * self.delay_seconds / 60:.1f} minutes"
        }
        
        return result 